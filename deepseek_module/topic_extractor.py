"""–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —á–µ—Ä–µ–∑ DeepSeek"""

import re
from typing import Any

from openai import AsyncOpenAI

from logger import format_log, get_logger

from .config import DeepSeekConfig

logger = get_logger(__name__)


class TopicExtractor:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—è MapReduce –ø–æ–¥—Ö–æ–¥"""

    def __init__(self, config: DeepSeekConfig):
        self.config = config

        if "deepseek.com" not in config.base_url.lower():
            raise ValueError(
                f"‚ùå –û–®–ò–ë–ö–ê: –£–∫–∞–∑–∞–Ω –Ω–µ DeepSeek endpoint! "
                f"–ü–æ–ª—É—á–µ–Ω: {config.base_url}, –æ–∂–∏–¥–∞–µ—Ç—Å—è: https://api.deepseek.com/v1"
            )

        self.client = AsyncOpenAI(
            api_key=config.api_key,
            base_url=config.base_url,
        )
        logger.info(
            format_log(
                "TopicExtractor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                –±–∞–∑–æ–≤—ã–π_url=config.base_url,
                –º–æ–¥–µ–ª—å=config.model,
            )
        )

    async def extract_topics(
        self,
        transcription_text: str,
        segments: list[dict] | None = None,
        recording_topic: str | None = None,
        granularity: str = "long",  # "short" | "long"
    ) -> dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —á–µ—Ä–µ–∑ DeepSeek.

        Args:
            transcription_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
            recording_topic: –ù–∞–∑–≤–∞–Ω–∏–µ –∫—É—Ä—Å–∞/–ø—Ä–µ–¥–º–µ—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ç–µ–º–∞–º–∏:
            {
                'topic_timestamps': [
                    {'topic': str, 'start': float, 'end': float},
                    ...
                ],
                'main_topics': [str, ...]  # –ú–∞–∫—Å–∏–º—É–º 2 —Ç–µ–º—ã
                'long_pauses': [
                    {'start': float, 'end': float, 'duration_minutes': float},
                    ...
                ]  # –ü–∞—É–∑—ã >=8 –º–∏–Ω—É—Ç –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
            }
        """
        if not segments or len(segments) == 0:
            raise ValueError("–°–µ–≥–º–µ–Ω—Ç—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º")

        logger.info(
            format_log(
                "–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞",
                –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å–µ–≥–º–µ–Ω—Ç–æ–≤=len(segments),
            )
        )
        if recording_topic:
            logger.info(
                format_log(
                    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏",
                    —Ç–µ–º–∞_–∑–∞–ø–∏—Å–∏=recording_topic,
                )
            )

        total_duration = segments[-1].get('end', 0) if segments else 0
        duration_minutes = total_duration / 60
        logger.info(
            format_log(
                "–†–∞—Å—Å—á–∏—Ç–∞–Ω–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ",
                –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω—É—Ç=round(duration_minutes, 1),
            )
        )

        min_topics, max_topics = self._calculate_topic_range(duration_minutes, granularity=granularity)
        logger.info(
            format_log(
                "–†–∞—Å—Å—á–∏—Ç–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–µ–º",
                –º–∏–Ω–∏–º—É–º_—Ç–µ–º=min_topics,
                –º–∞–∫—Å–∏–º—É–º_—Ç–µ–º=max_topics,
                –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω—É—Ç=round(duration_minutes, 1),
            )
        )

        transcript_with_timestamps = self._format_transcript_with_timestamps(segments)
        try:
            result = await self._analyze_full_transcript(
                transcript_with_timestamps,
                total_duration,
                recording_topic,
                min_topics,
                max_topics,
                granularity=granularity,
                segments=segments,
            )

            main_topics = result.get('main_topics', [])
            topic_timestamps = result.get('topic_timestamps', [])

            topic_timestamps_with_end = self._add_end_timestamps(topic_timestamps, total_duration)

            logger.info(
                format_log(
                    "–¢–µ–º—ã —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã",
                    –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–æ—Å–Ω–æ–≤–Ω—ã—Ö=len(main_topics),
                    –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö=len(topic_timestamps_with_end),
                )
            )

            return {
                'topic_timestamps': topic_timestamps_with_end,
                'main_topics': main_topics,
                'long_pauses': result.get('long_pauses', []),
            }
        except Exception as error:
            logger.exception(
                format_log(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–º—ã",
                    –æ—à–∏–±–∫–∞=str(error),
                )
            )
            return {
                'topic_timestamps': [],
                'main_topics': [],
            }

    def _format_transcript_with_timestamps(self, segments: list[dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.

        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        """
        segments_text = []
        noise_patterns = [
            r"—Ä–µ–¥–∞–∫—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤",
            r"–∫–æ—Ä—Ä–µ–∫—Ç–æ—Ä",
            r"–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç",
        ]
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º, –µ—Å—Ç—å –ª–∏ –¥–ª–∏–Ω–Ω–æ–µ –æ–∫–Ω–æ —à—É–º–∞ (15+ –º–∏–Ω—É—Ç –ø–æ–¥—Ä—è–¥)
        noise_times = []
        for seg in segments:
            text0 = (seg.get('text') or '').strip().lower()
            if text0 and any(re.search(pat, text0) for pat in noise_patterns):
                try:
                    noise_times.append(float(seg.get('start', 0)))
                except Exception:
                    pass
        exclude_from = None
        exclude_to = None
        if noise_times:
            first_noise = min(noise_times)
            last_noise = max(noise_times)
            if (last_noise - first_noise) >= 15 * 60:
                exclude_from, exclude_to = first_noise, last_noise

        for seg in segments:
            start = seg.get('start', 0)
            text = seg.get('text', '').strip()
            if text:
                lowered = text.lower()
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —à—É–º–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                if any(re.search(pat, lowered) for pat in noise_patterns):
                    continue
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë, —á—Ç–æ –ø–æ–ø–∞–ª–æ –≤ –¥–ª–∏–Ω–Ω–æ–µ –æ–∫–Ω–æ —à—É–º–∞
                if exclude_from is not None and exclude_to is not None:
                    try:
                        if exclude_from <= float(start) <= exclude_to:
                            continue
                    except Exception:
                        pass
                hours = int(start // 3600)
                minutes = int((start % 3600) // 60)
                seconds = int(start % 60)
                time_str = f"[{hours:02d}:{minutes:02d}:{seconds:02d}]"
                segments_text.append(f"{time_str} {text}")

        return "\n".join(segments_text)

    def _calculate_topic_range(self, duration_minutes: float, granularity: str = "long") -> tuple[int, int]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Ç–æ–ø–∏–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä—ã.

        –†–µ–∂–∏–º—ã:
        - long (–¥–ª–∏–Ω–Ω—ã–π —Ä–µ–∂–∏–º, –¥–µ—Ç–∞–ª—å–Ω–µ–µ):
          - 50 –º–∏–Ω—É—Ç -> 10‚Äì14
          - 90 –º–∏–Ω—É—Ç -> 14‚Äì20
          - 120 –º–∏–Ω—É—Ç -> 18‚Äì24
          - 180 –º–∏–Ω—É—Ç -> 22‚Äì28
        - short (–∫–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∂–∏–º, –∫—Ä—É–ø–Ω–µ–µ):
          - 50 –º–∏–Ω—É—Ç -> 3‚Äì5
          - 90 –º–∏–Ω—É—Ç -> 5‚Äì8
          - 120 –º–∏–Ω—É—Ç -> 6‚Äì9
          - 180 –º–∏–Ω—É—Ç -> 8‚Äì12

        Args:
            duration_minutes: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä—ã –≤ –º–∏–Ω—É—Ç–∞—Ö
            granularity: "short" –∏–ª–∏ "long"

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (min_topics, max_topics)
        """
        duration_minutes = max(50, min(180, duration_minutes))

        if granularity == "short":
            # –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∂–∏–º: –º–µ–Ω—å—à–µ —Ç–µ–º, –∫—Ä—É–ø–Ω–µ–µ (5-10 —Ç–µ–º –¥–ª—è 90-–º–∏–Ω—É—Ç–Ω–æ–π –ª–µ–∫—Ü–∏–∏)
            min_topics = int(3 + (duration_minutes - 50) * 4 / 130)
            max_topics = int(5 + (duration_minutes - 50) * 5 / 130)
            min_topics = max(3, min(8, min_topics))
            max_topics = max(5, min(12, max_topics))
            return min_topics, max_topics

        min_topics = int(10 + (duration_minutes - 50) * 8 / 130)
        max_topics = int(16 + (duration_minutes - 50) * 10 / 130)
        min_topics = max(10, min(18, min_topics))
        max_topics = max(16, min(26, max_topics))

        return min_topics, max_topics

    async def _analyze_full_transcript(
        self,
        transcript: str,
        total_duration: float,
        recording_topic: str | None = None,
        min_topics: int = 10,
        max_topics: int = 30,
        granularity: str = "long",  # "short" | "long"
        segments: list[dict] | None = None,
    ) -> dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —á–µ—Ä–µ–∑ DeepSeek.

        Args:
            transcript: –ü–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
            total_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            recording_topic: –ù–∞–∑–≤–∞–Ω–∏–µ –∫—É—Ä—Å–∞/–ø—Ä–µ–¥–º–µ—Ç–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏ –∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–ø–∏–∫–∞–º–∏
        """
        context_line = ""
        if recording_topic:
            context_line = f"\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: —ç—Ç–æ –ª–µ–∫—Ü–∏—è –ø–æ –∫—É—Ä—Å—É '{recording_topic}'.\n"

        if granularity == "short":
            min_spacing_minutes = max(10, min(18, total_duration / 60 * 0.12))
        else:  # granularity == "long"
            min_spacing_minutes = max(4, min(6, total_duration / 60 * 0.05))

        long_pauses = self._detect_long_pauses(segments or [], min_gap_minutes=8)
        pauses_instruction = ""
        if long_pauses:
            pauses_lines = [
                f"- {self._format_time(pause['start'])} ‚Äì {self._format_time(pause['end'])} (‚âà{pause['duration_minutes']:.1f} –º–∏–Ω)"
                for pause in long_pauses
            ]
            pauses_instruction = "\n\n‚ö†Ô∏è –í–ê–ñ–ù–û: –ù–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ—Ä—ã–≤—ã >=8 –º–∏–Ω—É—Ç. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤—å –∏—Ö –≤ —Å–ø–∏—Å–æ–∫ —Ç–µ–º:\n" + "\n".join(pauses_lines) + "\n\n–î–ª—è –∫–∞–∂–¥–æ–π –ø–∞—É–∑—ã: [HH:MM:SS] - –ü–µ—Ä–µ—Ä—ã–≤ (–≥–¥–µ HH:MM:SS ‚Äî –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ)."

        if granularity == "short":
            # –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∂–∏–º: —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∫—Ä—É–ø–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —É—á–µ–±–Ω–æ–π –ª–µ–∫—Ü–∏–∏ –∏ –≤—ã–¥–µ–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:{context_line}{pauses_instruction}

## –û–°–ù–û–í–ù–ê–Ø –¢–ï–ú–ê –ü–ê–†–´

–í—ã–≤–µ–¥–∏ –†–û–í–ù–û –û–î–ù–£ —Ç–µ–º—É (2‚Äì3 —Å–ª–æ–≤–∞):{f" –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã –ù–ï –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫—É—Ä—Å–∞ '{recording_topic}'. –ï—Å–ª–∏ —Ç–µ–º–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–∞–∫–∏–µ —Å–ª–æ–≤–∞ ‚Äî —É–±–µ—Ä–∏ –∏—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫—É—Ä—Å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è '–ü—Ä–∏–∫–ª–∞–¥–Ω–æ–π Python', –∞ —Ç–µ–º–∞ '–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ Python', –Ω–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ '–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'." if recording_topic else ""}
–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã

–ü—Ä–∏–º–µ—Ä—ã: "Stable Diffusion", "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤", "Generative Models"

## –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–û–ü–ò–ö–ò ({min_topics}-{max_topics} —Ç–æ–ø–∏–∫–æ–≤)

–§–æ—Ä–º–∞—Ç: [HH:MM:SS] - –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {min_topics}-{max_topics} —Ç–æ–ø–∏–∫–æ–≤ (–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Å—è –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–º–µ–Ω—ã —Ç–µ–º).
2. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–æ 8‚Äì20 –º–∏–Ω—É—Ç –Ω–∞ —Ç–µ–º—É, –ù–û –ì–õ–ê–í–ù–û–ï ‚Äî —Å–º–µ–Ω–∞ —Ç–µ–º—ã –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –†–ï–ê–õ–¨–ù–û–ú–£ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏.
3. –ü–†–ò–û–†–ò–¢–ï–¢: –û–ø—Ä–µ–¥–µ–ª—è–π –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–º –ø–æ –°–û–î–ï–†–ñ–ê–ù–ò–Æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏, –∞ –Ω–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏. –¢–µ–º—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã (6-25 –º–∏–Ω—É—Ç), –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–∫—Ü–∏–∏.
4. –ï—Å–ª–∏ —è–≤–Ω–∞—è —Å–º–µ–Ω–∞ —Ç–µ–º—ã –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ä–∞–Ω—å—à–µ 8 –º–∏–Ω—É—Ç ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, —É–∫–∞–∂–∏ –µ—ë.
5. –ï—Å–ª–∏ –æ–¥–Ω–∞ —Ç–µ–º–∞ –¥–ª–∏—Ç—Å—è 20+ –º–∏–Ω—É—Ç –±–µ–∑ —è–≤–Ω—ã—Ö –ø–æ–¥—Ç–µ–º ‚Äî –æ—Å—Ç–∞–≤—å –µ—ë —Ü–µ–ª—å–Ω–æ–π.
6. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥ –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏: {min_spacing_minutes:.1f} –º–∏–Ω—É—Ç (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–º—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–Ω—ã–µ).
7. –ù–∞–∑–≤–∞–Ω–∏—è: 3‚Äì6 —Å–ª–æ–≤, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–ø–æ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏).
8. –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫.
9. –¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.

–§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê:
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {min_topics}-{max_topics} —Ç–µ–º
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –≤ –æ—Å–Ω–æ–≤–Ω–æ–º 8‚Äì20 –º–∏–Ω—É—Ç (–¥–æ–ø—É—Å—Ç–∏–º—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ —ç—Ç–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
- –ü–µ—Ä–µ—Ä—ã–≤—ã: –≤—Å–µ >=8 –º–∏–Ω—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã (–µ—Å–ª–∏ –±—ã–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
- –ì—Ä–∞–Ω–∏—Ü—ã —Ç–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –†–ï–ê–õ–¨–ù–´–ú —Å–º–µ–Ω–∞–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º

–ï—Å–ª–∏ –≤–∏–¥–∏—à—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ç–∫–∞ –ø–æ–ª—É—á–∏–ª–∞—Å—å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–æ–π (—Ä–æ–≤–Ω–æ –ø–æ X –º–∏–Ω—É—Ç) ‚Äî –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç—å –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é.

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:
{transcript}
"""
        else:
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —É—á–µ–±–Ω–æ–π –ª–µ–∫—Ü–∏–∏ –∏ –≤—ã–¥–µ–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:{context_line}{pauses_instruction}

## –û–°–ù–û–í–ù–ê–Ø –¢–ï–ú–ê –ü–ê–†–´

–í—ã–≤–µ–¥–∏ –†–û–í–ù–û –û–î–ù–£ —Ç–µ–º—É (2‚Äì3 —Å–ª–æ–≤–∞):{f" –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã –ù–ï –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫—É—Ä—Å–∞ '{recording_topic}'. –ï—Å–ª–∏ —Ç–µ–º–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–∞–∫–∏–µ —Å–ª–æ–≤–∞ ‚Äî —É–±–µ—Ä–∏ –∏—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫—É—Ä—Å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è '–ü—Ä–∏–∫–ª–∞–¥–Ω–æ–π Python', –∞ —Ç–µ–º–∞ '–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ Python', –Ω–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ '–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'." if recording_topic else ""}
–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã

–ü—Ä–∏–º–µ—Ä—ã: "Stable Diffusion", "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤", "Generative Models"

## –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–û–ü–ò–ö–ò ({min_topics}-{max_topics} —Ç–æ–ø–∏–∫–æ–≤)

–§–æ—Ä–º–∞—Ç: [HH:MM:SS] - –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {min_topics}-{max_topics} —Ç–æ–ø–∏–∫–æ–≤ (–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Å—è –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–º–µ–Ω—ã —Ç–µ–º).
2. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–æ 3‚Äì12 –º–∏–Ω—É—Ç –Ω–∞ —Ç–µ–º—É, –ù–û –ì–õ–ê–í–ù–û–ï ‚Äî —Å–º–µ–Ω–∞ —Ç–µ–º—ã –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –†–ï–ê–õ–¨–ù–û–ú–£ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏.
3. –ü–†–ò–û–†–ò–¢–ï–¢: –û–ø—Ä–µ–¥–µ–ª—è–π –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–º –ø–æ –°–û–î–ï–†–ñ–ê–ù–ò–Æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏, –∞ –Ω–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏. –¢–µ–º—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã (2-15 –º–∏–Ω—É—Ç), –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–∫—Ü–∏–∏.
4. –ï—Å–ª–∏ —è–≤–Ω–∞—è —Å–º–µ–Ω–∞ —Ç–µ–º—ã –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ 2 –º–∏–Ω—É—Ç—ã ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, —É–∫–∞–∂–∏ –µ—ë.
5. –ï—Å–ª–∏ –æ–¥–Ω–∞ —Ç–µ–º–∞ –¥–ª–∏—Ç—Å—è 15+ –º–∏–Ω—É—Ç –±–µ–∑ —è–≤–Ω—ã—Ö –ø–æ–¥—Ç–µ–º ‚Äî –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–∏.
6. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥ –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏: {min_spacing_minutes:.1f} –º–∏–Ω—É—Ç (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–º—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–Ω—ã–µ).
7. –ù–∞–∑–≤–∞–Ω–∏—è: 3‚Äì6 —Å–ª–æ–≤, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–ø–æ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏).
8. –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫.
9. –¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.

–§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê:
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {min_topics}-{max_topics} —Ç–µ–º
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –≤ –æ—Å–Ω–æ–≤–Ω–æ–º 3‚Äì12 –º–∏–Ω—É—Ç (–¥–æ–ø—É—Å—Ç–∏–º—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ —ç—Ç–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
- –ü–µ—Ä–µ—Ä—ã–≤—ã: –≤—Å–µ >=8 –º–∏–Ω—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã (–µ—Å–ª–∏ –±—ã–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
- –ì—Ä–∞–Ω–∏—Ü—ã —Ç–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –†–ï–ê–õ–¨–ù–´–ú —Å–º–µ–Ω–∞–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º

–ï—Å–ª–∏ –≤–∏–¥–∏—à—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ç–∫–∞ –ø–æ–ª—É—á–∏–ª–∞—Å—å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–æ–π (—Ä–æ–≤–Ω–æ –ø–æ X –º–∏–Ω—É—Ç) ‚Äî –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç—å –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é.

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:
{transcript}
"""

        try:
            response = await self.client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã ‚Äî —Å–∞–º—ã–π –ª—É—á—à–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–∞ –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–µ Computer Science. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ –≤—ã–¥–µ–ª—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–∫—Ü–∏–π."
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    },
                ],
                temperature=self.config.temperature if self.config.temperature and self.config.temperature > 0 else 0.05,
                top_p=1.0,
                frequency_penalty=0.0,
                presence_penalty=0.0,
                seed=self.config.seed if getattr(self.config, 'seed', None) is not None else None,
                max_tokens=self.config.max_tokens,
            )

            content = response.choices[0].message.content.strip()
            if not content:
                return {'main_topics': [], 'topic_timestamps': []}

            logger.debug(f"üìù –ü—Ä–æ–º–ø—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ DeepSeek (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):\n{prompt[:1000]}...")
            logger.debug(f"üìù –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç DeepSeek:\n{content}")

            parsed = self._parse_structured_response(content, total_duration)
            parsed['long_pauses'] = long_pauses
            logger.debug(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞: main_topics={parsed.get('main_topics')}, topic_timestamps={len(parsed.get('topic_timestamps', []))}")

            return parsed

        except Exception as error:
            logger.exception(
                format_log(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç",
                    –æ—à–∏–±–∫–∞=str(error),
                )
            )
            return {'main_topics': [], 'topic_timestamps': []}

    def _detect_long_pauses(self, segments: list[dict], min_gap_minutes: float = 8.0) -> list[dict]:
        """
        –ü–æ–∏—Å–∫ –¥–ª–∏–Ω–Ω—ã—Ö –ø–∞—É–∑ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏.

        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–æ–∂–∏–¥–∞–µ—Ç—Å—è –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
            min_gap_minutes: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—É–∑—ã (–≤ –º–∏–Ω—É—Ç–∞—Ö) –¥–ª—è —Ñ–∏–∫—Å–∞—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–∞—É–∑–∞–º–∏: [{"start": float, "end": float, "duration_minutes": float}, ...]
        """
        if not segments:
            return []

        min_gap_seconds = min_gap_minutes * 60
        pauses: list[dict] = []

        sorted_segments = sorted(segments, key=lambda s: s.get('start', 0))

        for idx in range(len(sorted_segments) - 1):
            current = sorted_segments[idx]
            nxt = sorted_segments[idx + 1]

            current_end = float(current.get('end', current.get('start', 0) or 0))
            next_start = float(nxt.get('start', 0) or 0)

            gap = next_start - current_end
            if gap >= min_gap_seconds:
                pauses.append(
                    {
                        'start': current_end,
                        'end': next_start,
                        'duration_minutes': gap / 60,
                    }
                )

        return pauses

    @staticmethod
    def _format_time(seconds: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–∫—É–Ω–¥ –≤ HH:MM:SS"""
        total_seconds = int(seconds)
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        secs = total_seconds % 60
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    def _parse_structured_response(self, text: str, total_duration: float) -> dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç DeepSeek.

        –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
        ## –û–°–ù–û–í–ù–´–ï –¢–ï–ú–´ –ü–ê–†–´
        - –¢–µ–º–∞ 1
        - –¢–µ–º–∞ 2

        ## –î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–û–ü–ò–ö–ò –° –¢–ê–ô–ú–ö–û–î–ê–ú–ò
        [HH:MM:SS] - [–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞]
        [HH:MM:SS] - [–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞]

        Args:
            text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç DeepSeek
            total_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏ –∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–ø–∏–∫–∞–º–∏
        """
        main_topics = []
        topic_timestamps = []

        lines = text.split('\n')

        in_main_topics = False
        in_detailed_topics = False
        main_topics_section_found = False

        timestamp_pattern = r'\[(\d{1,2}):(\d{2})(?::(\d{2}))?\]\s*[-‚Äì‚Äî]?\s*(.+)'

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–µ–º—É –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞ (–¥–æ —Å–µ–∫—Ü–∏–∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–ø–∏–∫–æ–≤)
        found_main_topic_before_section = False
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            if not line_stripped:
                continue

            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–µ–∫—Ü–∏—é –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–ø–∏–∫–æ–≤, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ –Ω–µ—ë
            if '–î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–û–ü–ò–ö–ò' in line_stripped.upper() or '–¢–û–ü–ò–ö–ò –° –¢–ê–ô–ú–ö–û–î–ê–ú–ò' in line_stripped.upper():
                # –ò—â–µ–º —Ç–µ–º—É –≤–æ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫–∞—Ö –¥–æ —ç—Ç–æ–π —Å–µ–∫—Ü–∏–∏ (–Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ - –º–∞–∫—Å–∏–º—É–º 10 —Å—Ç—Ä–æ–∫)
                for j in range(max(0, i - 10), i):
                    candidate = lines[j].strip()
                    if candidate and not candidate.startswith('##') and not candidate.startswith('#'):
                        if '–≤—ã–≤–µ–¥–∏' in candidate.lower() or '—Ç–µ–º–∞' in candidate.lower() or '–ø—Ä–∏–º–µ—Ä' in candidate.lower():
                            continue
                        if re.match(timestamp_pattern, candidate):
                            continue
                        topic_candidate = re.sub(r'^[-*‚Ä¢\d.)]+\s*', '', candidate).strip()
                        topic_candidate = re.sub(r'^\[.*?\]\s*', '', topic_candidate).strip()
                        if topic_candidate:
                            words = topic_candidate.split()
                            # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–π (2-4 —Å–ª–æ–≤–∞)
                            if 2 <= len(words) <= 4:
                                main_topics.append(topic_candidate if len(words) <= 3 else ' '.join(words[:3]))
                                logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ (–ø–µ—Ä–µ–¥ —Å–µ–∫—Ü–∏–µ–π –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–ø–∏–∫–æ–≤): {topic_candidate}")
                                found_main_topic_before_section = True
                                break
                break

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–µ–º—É –ø–µ—Ä–µ–¥ —Å–µ–∫—Ü–∏–µ–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—Ç–≤–µ—Ç–∞
        if not found_main_topic_before_section:
            for _, line in enumerate(lines[:10]):
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('##') or line_stripped.startswith('#'):
                    continue
                if re.match(timestamp_pattern, line_stripped):
                    break
                if '–≤—ã–≤–µ–¥–∏' in line_stripped.lower() or '—Ç–µ–º–∞' in line_stripped.lower() or '–ø—Ä–∏–º–µ—Ä' in line_stripped.lower():
                    continue
                topic_candidate = re.sub(r'^[-*‚Ä¢\d.)]+\s*', '', line_stripped).strip()
                topic_candidate = re.sub(r'^\[.*?\]\s*', '', topic_candidate).strip()
                if topic_candidate:
                    words = topic_candidate.split()
                    if 2 <= len(words) <= 4:
                        main_topics.append(topic_candidate if len(words) <= 3 else ' '.join(words[:3]))
                        logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ (–≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞): {topic_candidate}")
                        break

        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue

            if (
                '–û–°–ù–û–í–ù–´–ï –¢–ï–ú–´' in line.upper()
                or '–û–°–ù–û–í–ù–´–ï –¢–ï–ú–´ –ü–ê–†–´' in line.upper()
                or '–û–°–ù–û–í–ù–ê–Ø –¢–ï–ú–ê' in line.upper()
            ):
                in_main_topics = True
                in_detailed_topics = False
                main_topics_section_found = True
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if next_line and not next_line.startswith('##') and not next_line.startswith('#'):
                        topic_candidate = re.sub(r'^[-*‚Ä¢\d.)]+\s*', '', next_line).strip()
                        topic_candidate = re.sub(r'^\[.*?\]\s*', '', topic_candidate).strip()
                        if topic_candidate and len(topic_candidate) > 3 and '–≤—ã–≤–µ–¥–∏' not in topic_candidate.lower():
                            words = topic_candidate.split()
                            if len(words) <= 4:
                                main_topics.append(topic_candidate if len(words) <= 3 else ' '.join(words[:3]))
                                logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ (—Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞): {topic_candidate}")
                continue
            elif '–î–ï–¢–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–û–ü–ò–ö–ò' in line.upper() or '–¢–û–ü–ò–ö–ò –° –¢–ê–ô–ú–ö–û–î–ê–ú–ò' in line.upper():
                in_main_topics = False
                in_detailed_topics = True
                continue
            elif line.startswith('##'):
                in_main_topics = False
                in_detailed_topics = False
                continue

            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏ [HH:MM:SS], —ç—Ç–æ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–ø–∏–∫
            # (–¥–∞–∂–µ –µ—Å–ª–∏ –º—ã –Ω–µ –Ω–∞—à–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏)
            timestamp_match = re.match(timestamp_pattern, line)
            if timestamp_match:
                in_detailed_topics = True
                in_main_topics = False
                # –ü–∞—Ä—Å–∏–º —Ç–æ–ø–∏–∫ —Å—Ä–∞–∑—É
                hours_str, minutes_str, seconds_str, topic = timestamp_match.groups()
                if seconds_str is None:
                    hours = 0
                    minutes = int(hours_str)
                    seconds = int(minutes_str)
                else:
                    hours = int(hours_str)
                    minutes = int(minutes_str)
                    seconds = int(seconds_str)
                total_seconds = hours * 3600 + minutes * 60 + seconds
                if 0 <= total_seconds <= total_duration:
                    topic_timestamps.append({
                        'topic': topic.strip(),
                        'start': float(total_seconds),
                    })
                continue

            if in_main_topics:
                if not line or line.startswith('##') or line.startswith('#'):
                    continue

                topic = re.sub(r'^[-*‚Ä¢\d.)]+\s*', '', line).strip()
                topic = re.sub(r'^\[.*?\]\s*', '', topic).strip()

                if topic.startswith('[') and '–≤—ã–≤–µ–¥–∏' in topic.lower():
                    continue

                if topic and len(topic) > 3:
                    words = topic.split()
                    if len(words) > 7:
                        topic = ' '.join(words[:15]) + '...'
                    elif len(topic) > 150:
                        topic = topic[:150].rsplit(' ', 1)[0] + '...'
                    main_topics.append(topic)
                    logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞: {topic}")

            elif in_detailed_topics:
                match = re.match(timestamp_pattern, line)
                if match:
                    hours_str, minutes_str, seconds_str, topic = match.groups()

                    if seconds_str is None:
                        hours = 0
                        minutes = int(hours_str)
                        seconds = int(minutes_str)
                    else:
                        hours = int(hours_str)
                        minutes = int(minutes_str)
                        seconds = int(seconds_str)

                    total_seconds = hours * 3600 + minutes * 60 + seconds

                    if 0 <= total_seconds <= total_duration:
                        topic_timestamps.append({
                            'topic': topic.strip(),
                            'start': float(total_seconds),
                        })
                    else:
                        logger.debug(
                            format_log(
                                "–ú–µ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞: –≤–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞",
                                —Ç–µ–º–∞=topic.strip(),
                                –ø–æ–∑–∏—Ü–∏—è_–º–∏–Ω—É—Ç=round(total_seconds / 60, 1),
                                –¥–æ–ø—É—Å—Ç–∏–º—ã–π_–¥–∏–∞–ø–∞–∑–æ–Ω=f"0-{round(total_duration / 60, 1)}",
                            )
                        )

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ–ø–∏–∫–∏ —á–µ—Ä–µ–∑ —Å–µ–∫—Ü–∏–∏, –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        if not topic_timestamps:
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                match = re.match(timestamp_pattern, line)
                if match:
                    hours_str, minutes_str, seconds_str, topic = match.groups()
                    if seconds_str is None:
                        hours = 0
                        minutes = int(hours_str)
                        seconds = int(minutes_str)
                    else:
                        hours = int(hours_str)
                        minutes = int(minutes_str)
                        seconds = int(seconds_str)
                    total_seconds = hours * 3600 + minutes * 60 + seconds
                    if 0 <= total_seconds <= total_duration:
                        topic_timestamps.append({
                            'topic': topic.strip(),
                            'start': float(total_seconds),
                        })

        if not topic_timestamps and not main_topics:
            topic_timestamps = self._parse_simple_timestamps(text, total_duration)

        if main_topics_section_found and not main_topics:
            logger.debug("‚ö†Ô∏è –°–µ–∫—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ —Ç–µ–º—ã –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã. –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–º—É –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞...")
            for i, line in enumerate(lines):
                if '–û–°–ù–û–í–ù–´–ï –¢–ï–ú–´' in line.upper() or '–û–°–ù–û–í–ù–´–ï –¢–ï–ú–´ –ü–ê–†–´' in line.upper():
                    for j in range(i + 1, min(i + 5, len(lines))):
                        candidate = lines[j].strip()
                        if candidate and not candidate.startswith('##') and not candidate.startswith('#'):
                            topic_candidate = re.sub(r'^[-*‚Ä¢\d.)]+\s*', '', candidate).strip()
                            topic_candidate = re.sub(r'^\[.*?\]\s*', '', topic_candidate).strip()
                            if (topic_candidate and len(topic_candidate) > 3 and
                                '–≤—ã–≤–µ–¥–∏' not in topic_candidate.lower() and
                                '—Ç–µ–º–∞' not in topic_candidate.lower() and
                                '–ø—Ä–∏–º–µ—Ä' not in topic_candidate.lower()):
                                words = topic_candidate.split()
                                if 2 <= len(words) <= 4:
                                    main_topics.append(topic_candidate if len(words) <= 3 else ' '.join(words[:3]))
                                    logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ (fallback): {topic_candidate}")
                                    break
                    break

        processed_main_topics = []
        for topic in main_topics[:1]:
            topic = ' '.join(topic.split())
            if topic and len(topic) > 3:
                words = topic.split()
                if len(words) > 7:
                    topic = ' '.join(words[:7]) + '...'
                processed_main_topics.append(topic)

        if not processed_main_topics and main_topics_section_found:
            logger.warning(f"‚ö†Ô∏è –°–µ–∫—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–º—É. –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—Ç–≤–µ—Ç–∞:\n{chr(10).join(lines[:10])}")

        return {
            'main_topics': processed_main_topics,
            'topic_timestamps': topic_timestamps,
        }

    def _parse_simple_timestamps(self, text: str, total_duration: float) -> list[dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (fallback).

        –§–æ—Ä–º–∞—Ç: [HH:MM:SS] - [–ù–∞–∑–≤–∞–Ω–∏–µ] –∏–ª–∏ [HH:MM:SS] [–ù–∞–∑–≤–∞–Ω–∏–µ]

        Args:
            text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            total_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ

        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
        """
        timestamps = []
        lines = text.split('\n')

        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è [HH:MM:SS] - [–ù–∞–∑–≤–∞–Ω–∏–µ] –∏–ª–∏ [HH:MM:SS] [–ù–∞–∑–≤–∞–Ω–∏–µ]
        pattern = r'\[(\d{1,2}):(\d{2})(?::(\d{2}))?\]\s*[-‚Äì‚Äî]?\s*(.+)'

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            match = re.match(pattern, line)
            if match:
                hours_str, minutes_str, seconds_str, topic = match.groups()

                if seconds_str is None:
                    hours = 0
                    minutes = int(hours_str)
                    seconds = int(minutes_str)
                else:
                    hours = int(hours_str)
                    minutes = int(minutes_str)
                    seconds = int(seconds_str)

                total_seconds = hours * 3600 + minutes * 60 + seconds

                if 0 <= total_seconds <= total_duration:
                    timestamps.append({
                        'topic': topic.strip(),
                        'start': float(total_seconds),
                    })

        return timestamps

    def _filter_and_merge_topics(
        self, timestamps: list[dict], total_duration: float, min_topics: int = 10, max_topics: int = 30
    ) -> list[dict]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–æ–ø–∏–∫–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω—É–∂–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞.

        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–ª–∏–∑–∫–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Ç–æ–ø–∏–∫–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ.

        Args:
            timestamps: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–æ–ø–∏–∫–æ–≤ —Å start
            total_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            min_topics: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–∏–∫–æ–≤
            max_topics: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–∏–∫–æ–≤

        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–ø–∏–∫–æ–≤
        """
        if not timestamps:
            return []

        duration_minutes = total_duration / 60
        min_spacing = max(180, min(300, duration_minutes * 60 * 0.04))

        sorted_timestamps = sorted(timestamps, key=lambda x: x.get('start', 0))

        if len(sorted_timestamps) <= max_topics:
            merged = []

            for ts in sorted_timestamps:
                start = ts.get('start', 0)
                topic = ts.get('topic', '').strip()

                if not topic:
                    continue

                if merged and (start - merged[-1].get('start', 0)) < min_spacing:
                    prev_topic = merged[-1].get('topic', '')
                    if len(topic) > len(prev_topic):
                        merged[-1]['topic'] = topic
                    if start < merged[-1].get('start', 0):
                        merged[-1]['start'] = start
                else:
                    merged.append(ts)

            return merged

        target_count = max_topics
        step = len(sorted_timestamps) / target_count

        filtered = []
        for i in range(target_count):
            idx = int(i * step)
            if idx < len(sorted_timestamps):
                filtered.append(sorted_timestamps[idx])

        merged = []

        for ts in filtered:
            start = ts.get('start', 0)
            topic = ts.get('topic', '').strip()

            if not topic:
                continue

            if merged and (start - merged[-1].get('start', 0)) < min_spacing:
                prev_topic = merged[-1].get('topic', '')
                if len(topic) > len(prev_topic):
                    merged[-1]['topic'] = topic
                if start < merged[-1].get('start', 0):
                    merged[-1]['start'] = start
            else:
                merged.append(ts)

        if len(merged) < min_topics:
            additional_step = len(sorted_timestamps) / (min_topics - len(merged))
            added_indices = set()

            for i in range(min_topics - len(merged)):
                idx = int(i * additional_step)
                if idx < len(sorted_timestamps):
                    if idx not in added_indices:
                        ts = sorted_timestamps[idx]
                        start = ts.get('start', 0)
                        topic = ts.get('topic', '').strip()

                        if topic:
                            too_close = False
                            for existing in merged:
                                if abs(start - existing.get('start', 0)) < min_spacing:
                                    too_close = True
                                    break

                            if not too_close:
                                merged.append(ts)
                                added_indices.add(idx)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            merged = sorted(merged, key=lambda x: x.get('start', 0))

        return merged

    def _add_end_timestamps(self, timestamps: list[dict], total_duration: float) -> list[dict]:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ end –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã.

        Args:
            timestamps: –°–ø–∏—Å–æ–∫ —Ç–µ–º —Å start
            total_duration: –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–µ–º —Å start –∏ end
        """
        if not timestamps:
            return []

        sorted_timestamps = sorted(timestamps, key=lambda x: x.get('start', 0))

        result = []
        for i, ts in enumerate(sorted_timestamps):
            start = ts.get('start', 0)
            topic = ts.get('topic', '').strip()

            if not topic:
                continue

            if i < len(sorted_timestamps) - 1:
                end = sorted_timestamps[i + 1].get('start', 0)
            else:
                end = total_duration

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if end - start < 60 and i < len(sorted_timestamps) - 1:
                end = min(start + 60, sorted_timestamps[i + 1].get('start', 0))

            end = min(end, total_duration)

            if start >= end:
                logger.warning(
                    format_log(
                        "–¢–µ–º–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞ –∏–∑-–∑–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫",
                        —Ç–µ–º–∞=topic,
                        –Ω–∞—á–∞–ª–æ_—Å–µ–∫—É–Ω–¥=round(start, 1),
                        –∫–æ–Ω–µ—Ü_—Å–µ–∫—É–Ω–¥=round(end, 1),
                    )
                )
                continue

            result.append({
                'topic': topic,
                'start': start,
                'end': end,
            })

        return result


