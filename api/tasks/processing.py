"""Celery tasks –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–µ–π —Å multi-tenancy support."""

import asyncio
from pathlib import Path

from celery import Task
from celery.exceptions import SoftTimeLimitExceeded

from api.celery_app import celery_app
from api.repositories.recording_repos import RecordingAsyncRepository
from database.config import DatabaseConfig
from database.manager import DatabaseManager
from logger import get_logger
from models import MeetingRecording, ProcessingStageType, ProcessingStatus
from video_download_module.downloader import ZoomDownloader
from video_processing_module.video_processor import VideoProcessor

logger = get_logger()


class ProcessingTask(Task):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å multi-tenancy."""

    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –∑–∞–¥–∞—á–∏."""
        user_id = kwargs.get("user_id", "unknown")
        recording_id = kwargs.get("recording_id", "unknown")
        logger.error(f"Task {task_id} for user {user_id}, recording {recording_id} failed: {exc!r}")

    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏."""
        user_id = kwargs.get("user_id", "unknown")
        logger.warning(f"Task {task_id} for user {user_id} retrying: {exc}")

    def on_success(self, retval, task_id, args, kwargs):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."""
        user_id = kwargs.get("user_id", "unknown")
        logger.info(f"Task {task_id} for user {user_id} completed successfully")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.download_recording",
    max_retries=3,
    default_retry_delay=600,
)
def download_recording_task(
    self,
    recording_id: int,
    user_id: int,
    force: bool = False,
) -> dict:
    """
    –°–∫–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –∏–∑ Zoom.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        force: –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ—Å–ª–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω–æ

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    try:
        logger.info(f"[Task {self.request.id}] Downloading recording {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing download...', 'step': 'download'}
        )

        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            _async_download_recording(self, recording_id, user_id, force)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=900, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error downloading: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_download_recording(task_self, recording_id: int, user_id: int, force: bool) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è."""
    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º download_url
        download_url = None
        if recording.source and recording.source.meta:
            download_url = recording.source.meta.get("download_url")

        if not download_url:
            raise ValueError("No download URL available. Please sync from Zoom first.")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ —Å–∫–∞—á–∞–Ω–æ —É–∂–µ
        if not force and recording.status == ProcessingStatus.DOWNLOADED and recording.local_video_path:
            if Path(recording.local_video_path).exists():
                return {
                    "success": True,
                    "message": "Already downloaded",
                    "local_video_path": recording.local_video_path,
                }

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 30, 'status': 'Downloading from Zoom...', 'step': 'download'}
        )

        # –°–æ–∑–¥–∞–µ–º downloader
        user_download_dir = f"media/user_{user_id}/video/unprocessed"
        downloader = ZoomDownloader(download_dir=user_download_dir)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ MeetingRecording
        meeting_id = recording.source.source_key if recording.source else str(recording.id)
        file_size = recording.source.meta.get("file_size", 0) if recording.source and recording.source.meta else 0
        download_access_token = recording.source.meta.get("download_access_token") if recording.source and recording.source.meta else None
        passcode = recording.source.meta.get("recording_play_passcode") if recording.source and recording.source.meta else None
        password = recording.source.meta.get("password") if recording.source and recording.source.meta else None
        account = recording.source.meta.get("account") if recording.source and recording.source.meta else None

        meeting_recording = MeetingRecording({
            "id": meeting_id,
            "uuid": meeting_id,
            "topic": recording.display_name,
            "start_time": recording.start_time.isoformat(),
            "duration": recording.duration or 0,
            "account": account or "default",
            "recording_files": [{
                "file_type": "MP4",
                "file_size": file_size,
                "download_url": download_url,
                "recording_type": "shared_screen_with_speaker_view",
                "download_access_token": download_access_token,
            }],
            "password": password,
            "recording_play_passcode": passcode,
        })
        meeting_recording.db_id = recording.id

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 50, 'status': 'Saving video file...', 'step': 'download'}
        )

        # –°–∫–∞—á–∏–≤–∞–µ–º
        success = await downloader.download_recording(meeting_recording, force_download=force)

        if success:
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 90, 'status': 'Updating database...', 'step': 'download'}
            )

            recording.local_video_path = meeting_recording.local_video_path
            recording.status = ProcessingStatus.DOWNLOADED
            await recording_repo.update(recording)
            await session.commit()

            return {
                "success": True,
                "local_video_path": recording.local_video_path,
            }
        else:
            raise Exception("Download failed")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.process_video",
    max_retries=2,
    default_retry_delay=300,
)
def process_video_task(
    self,
    recording_id: int,
    user_id: int,
    silence_threshold: float = -40.0,
    min_silence_duration: float = 2.0,
    padding_before: float = 5.0,
    padding_after: float = 5.0,
) -> dict:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ (FFmpeg - —É–¥–∞–ª–µ–Ω–∏–µ —Ç–∏—à–∏–Ω—ã).

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        silence_threshold: –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –≤ –¥–ë
        min_silence_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã
        padding_before: –û—Ç—Å—Ç—É–ø –¥–æ –∑–≤—É–∫–∞
        padding_after: –û—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ –∑–≤—É–∫–∞

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        logger.info(f"[Task {self.request.id}] Processing video {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing video processing...', 'step': 'process'}
        )

        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            _async_process_video(
                self,
                recording_id,
                user_id,
                silence_threshold,
                min_silence_duration,
                padding_before,
                padding_after,
            )
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error processing: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_process_video(
    task_self,
    recording_id: int,
    user_id: int,
    silence_threshold: float,
    min_silence_duration: float,
    padding_before: float,
    padding_after: float,
) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ."""
    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        if not recording.local_video_path:
            raise ValueError("No video file available. Please download first.")

        if not Path(recording.local_video_path).exists():
            raise ValueError(f"Video file not found: {recording.local_video_path}")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Analyzing video...', 'step': 'process'}
        )

        # –°–æ–∑–¥–∞–µ–º processor —Å ProcessingConfig
        from video_processing_module.config import ProcessingConfig

        user_processed_dir = f"media/user_{user_id}/video/processed"
        config = ProcessingConfig(
            silence_threshold=silence_threshold,
            min_silence_duration=min_silence_duration,
            padding_before=padding_before,
            padding_after=padding_after,
            output_dir=user_processed_dir,
        )
        processor = VideoProcessor(config)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 40, 'status': 'Processing with FFmpeg...', 'step': 'process'}
        )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –∑–≤—É–∫–∞
        success, processed_path = await processor.process_video_with_audio_detection(
            video_path=recording.local_video_path,
            title=recording.display_name,
            start_time=recording.start_time.isoformat(),
        )

        if success and processed_path:
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 60, 'status': 'Extracting audio from processed video...', 'step': 'extract_audio'}
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            import subprocess

            from utils.file_utils import sanitize_filename

            audio_dir = f"media/user_{user_id}/audio/processed"
            Path(audio_dir).mkdir(parents=True, exist_ok=True)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
            safe_title = sanitize_filename(recording.display_name)
            date_suffix = ""
            try:
                date_obj = recording.start_time
                date_suffix = f"_{date_obj.strftime('%y-%m-%d_%H-%M')}"
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã –¥–ª—è –∞—É–¥–∏–æ: {e}")

            audio_filename = f"{safe_title}{date_suffix}_processed.mp3"
            audio_path = str(Path(audio_dir) / audio_filename)

            logger.info(f"üéµ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {recording.display_name}")

            # FFmpeg –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ (64k, 16kHz, mono)
            extract_cmd = [
                "ffmpeg",
                "-i", processed_path,
                "-vn",  # –±–µ–∑ –≤–∏–¥–µ–æ
                "-acodec", "libmp3lame",
                "-ab", "64k",
                "-ar", "16000",
                "-ac", "1",  # mono
                "-y",  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                audio_path,
            ]

            try:
                extract_process = await asyncio.create_subprocess_exec(
                    *extract_cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
                stdout, stderr = await extract_process.communicate()

                if extract_process.returncode == 0 and Path(audio_path).exists():
                    recording.processed_audio_dir = audio_dir
                    logger.info(f"‚úÖ –ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {audio_path}")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ: {stderr.decode()}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e}")

            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 90, 'status': 'Updating database...', 'step': 'process'}
            )

            recording.processed_video_path = processed_path
            recording.status = ProcessingStatus.PROCESSED
            # VIDEO_PROCESSING - —ç—Ç–æ —á–∞—Å—Ç—å –æ–±—â–µ–≥–æ ProcessingStatus.PROCESSED, –Ω–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º
            await recording_repo.update(recording)
            await session.commit()

            return {
                "success": True,
                "processed_video_path": processed_path,
                "audio_path": audio_path if Path(audio_path).exists() else None,
            }
        else:
            raise Exception("Processing failed")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.transcribe_recording",
    max_retries=2,
    default_retry_delay=300,
)
def transcribe_recording_task(
    self,
    recording_id: int,
    user_id: int,
) -> dict:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ —Å –ê–î–ú–ò–ù–°–ö–ò–ú–ò –∫—Ä–µ–¥–∞–º–∏.

    –í–ê–ñ–ù–û: –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (Fireworks), –ë–ï–ó –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º.
    –î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ extract_topics_task.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (–±–µ–∑ —Ç–æ–ø–∏–∫–æ–≤)
    """
    try:
        logger.info(f"[Task {self.request.id}] Transcribing recording {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing transcription...', 'step': 'transcribe'}
        )

        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            _async_transcribe_recording(self, recording_id, user_id)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error transcribing: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_transcribe_recording(task_self, recording_id: int, user_id: int) -> dict:
    """
    Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å –ê–î–ú–ò–ù–°–ö–ò–ú–ò –ö–†–ï–î–ê–ú–ò.

    –í–ê–ñ–ù–û: –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (Fireworks), –±–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º.
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –¥–µ–ª–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ /topics endpoint.
    """
    from fireworks_module import FireworksConfig, FireworksTranscriptionService
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ > –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ > –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ
        audio_path = None

        # 1. –ò—â–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª
        if recording.processed_audio_dir:
            audio_dir = Path(recording.processed_audio_dir)
            if audio_dir.exists():
                for ext in ("*.mp3", "*.wav", "*.m4a"):
                    audio_files = sorted(audio_dir.glob(ext))
                    if audio_files:
                        audio_path = str(audio_files[0])
                        logger.info(f"üéµ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ: {audio_path}")
                        break

        # 2. Fallback –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ
        if not audio_path:
            audio_path = recording.processed_video_path or recording.local_video_path
            if audio_path:
                logger.info(f"üé¨ –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ —Ñ–∞–π–ª (–∞—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ): {audio_path}")

        if not audio_path:
            raise ValueError("No audio or video file available for transcription")

        if not Path(audio_path).exists():
            raise ValueError(f"Audio/video file not found: {audio_path}")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Loading transcription service...', 'step': 'transcribe'}
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ê–î–ú–ò–ù–°–ö–ò–ï –∫—Ä–µ–¥—ã (—Ç–æ–ª—å–∫–æ Fireworks)
        fireworks_config = FireworksConfig.from_file("config/fireworks_creds.json")
        fireworks_service = FireworksTranscriptionService(fireworks_config)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 30, 'status': 'Transcribing audio...', 'step': 'transcribe'}
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Fireworks
        from transcription_module.service import TranscriptionService

        fireworks_prompt = TranscriptionService._compose_fireworks_prompt(
            fireworks_config.prompt, recording.display_name
        )

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–µ—Ä–µ–∑ Fireworks API (–¢–û–õ–¨–ö–û —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è, –±–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º)
        transcription_result = await fireworks_service.transcribe_audio(
            audio_path=audio_path,
            language=fireworks_config.language,
            prompt=fireworks_prompt,
        )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 70, 'status': 'Saving transcription...', 'step': 'transcribe'}
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ master.json (–ë–ï–ó topics.json)
        transcription_manager = get_transcription_manager()
        transcription_dir = transcription_manager.get_dir(recording_id)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        words = transcription_result.get("words", [])
        segments = transcription_result.get("segments", [])
        language = transcription_result.get("language", "ru")

        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        duration = 0.0
        if segments and len(segments) > 0:
            last_segment = segments[-1]
            duration = last_segment.get("end", 0.0)

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–¥–º–∏–Ω–∞ (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏)
        usage_metadata = {
            "model": fireworks_config.model,
            "prompt_used": fireworks_prompt,
            "config": {
                "temperature": fireworks_config.temperature,
                "language": fireworks_config.language,
                "response_format": fireworks_config.response_format,
                "timestamp_granularities": fireworks_config.timestamp_granularities,
                "preprocessing": fireworks_config.preprocessing,
            },
            "audio_file": {
                "path": audio_path,
                "duration_seconds": duration,
            },
            # –ï—Å–ª–∏ Fireworks API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç usage, –¥–æ–±–∞–≤–ª—è–µ–º —Å—é–¥–∞
            "usage": transcription_result.get("usage"),
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º master.json
        transcription_manager.save_master(
            recording_id=recording_id,
            words=words,
            segments=segments,
            language=language,
            model="fireworks",
            duration=duration,
            usage_metadata=usage_metadata,
            user_id=user_id,
            raw_response=transcription_result,
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—ç—à-—Ñ–∞–π–ª—ã (segments.txt, words.txt)
        transcription_manager.generate_cache_files(recording_id, user_id=user_id)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 90, 'status': 'Updating database...', 'step': 'transcribe'}
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î (–±–µ–∑ —Ç–æ–ø–∏–∫–æ–≤)
        recording.transcription_dir = str(transcription_dir)
        recording.transcription_info = transcription_result

        # –ü–æ–º–µ—á–∞–µ–º —ç—Ç–∞–ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π
        recording.mark_stage_completed(
            ProcessingStageType.TRANSCRIBE,
            meta={"transcription_dir": str(transcription_dir), "language": language, "model": "fireworks"},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ processing_stages
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        logger.info(
            f"‚úÖ Transcription completed for recording {recording_id}: "
            f"words={len(words)}, segments={len(segments)}, language={language}"
        )

        return {
            "success": True,
            "transcription_dir": str(transcription_dir),
            "language": language,
            "words_count": len(words),
            "segments_count": len(segments),
        }


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.full_pipeline",
    max_retries=1,
    default_retry_delay=600,
)
def full_pipeline_task(
    self,
    recording_id: int,
    user_id: int,
    download: bool = True,
    process: bool = True,
    transcribe: bool = True,
    upload: bool = False,
    platforms: list[str] | None = None,
    preset_ids: dict[str, int] | None = None,
    granularity: str = "long",
    process_config: dict | None = None,
) -> dict:
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏: download ‚Üí process ‚Üí transcribe ‚Üí upload.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        download: –í—ã–ø–æ–ª–Ω–∏—Ç—å download
        process: –í—ã–ø–æ–ª–Ω–∏—Ç—å process
        transcribe: –í—ã–ø–æ–ª–Ω–∏—Ç—å transcribe
        upload: –í—ã–ø–æ–ª–Ω–∏—Ç—å upload
        platforms: –°–ø–∏—Å–æ–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        preset_ids: –°–ª–æ–≤–∞—Ä—å {platform: preset_id}
        granularity: –†–µ–∂–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º
        process_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    try:
        logger.info(f"[Task {self.request.id}] Full pipeline for recording {recording_id}, user {user_id}")

        from api.tasks.upload import upload_recording_to_platform

        platforms = platforms or []
        process_config = process_config or {}

        results = {
            "recording_id": recording_id,
            "steps_completed": [],
            "errors": [],
        }

        total_steps = sum([download, process, transcribe, upload and len(platforms) > 0])
        current_step = 0

        # STEP 1: Download
        if download:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Downloading from Zoom...',
                        'step': 'download'
                    }
                )

                download_result = download_recording_task.apply(
                    args=[recording_id, user_id, False]
                ).get()

                results["steps_completed"].append("download")
                results["download"] = download_result["result"]
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Download failed: {str(e)}")
                logger.error(f"Download step failed: {e}")

        # STEP 2: Process
        if process:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Processing video...',
                        'step': 'process'
                    }
                )

                process_result = process_video_task.apply(
                    args=[recording_id, user_id],
                    kwargs=process_config,
                ).get()

                results["steps_completed"].append("process")
                results["process"] = process_result["result"]
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Processing failed: {str(e)}")
                logger.error(f"Processing step failed: {e}")

        # STEP 3: Transcribe
        if transcribe:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Transcribing...',
                        'step': 'transcribe'
                    }
                )

                transcribe_result = transcribe_recording_task.apply(
                    args=[recording_id, user_id]
                ).get()

                results["steps_completed"].append("transcribe")
                results["transcribe"] = transcribe_result["result"]
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Transcription failed: {str(e)}")
                logger.error(f"Transcription step failed: {e}")

        # STEP 4: Upload
        if upload and platforms:
            upload_results = []
            for platform in platforms:
                try:
                    self.update_state(
                        state='PROCESSING',
                        meta={
                            'progress': int((current_step / total_steps) * 100),
                            'status': f'Uploading to {platform}...',
                            'step': 'upload'
                        }
                    )

                    preset_id = preset_ids.get(platform) if preset_ids else None

                    upload_result = upload_recording_to_platform.apply(
                        args=[recording_id, user_id, platform, preset_id]
                    ).get()

                    upload_results.append(upload_result["result"])
                except Exception as e:
                    results["errors"].append(f"Upload to {platform} failed: {str(e)}")
                    logger.error(f"Upload to {platform} failed: {e}")

            if upload_results:
                results["steps_completed"].append("upload")
                results["upload"] = upload_results
                current_step += 1

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        if not results["errors"]:
            results["status"] = "completed"
        elif results["steps_completed"]:
            results["status"] = "partially_completed"
        else:
            results["status"] = "failed"

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": results,
        }

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Full pipeline failed: {exc!r}", exc_info=True)
        raise


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.extract_topics",
    max_retries=2,
    default_retry_delay=300,
)
def extract_topics_task(
    self,
    recording_id: int,
    user_id: int,
    granularity: str = "long",
    version_id: str | None = None,
) -> dict:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–µ–º—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—Å–∫–∏–µ –∫—Ä–µ–¥—ã).

    –ú–æ–¥–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –∏ —Ñ–æ–ª–ª–±—ç–∫–∞–º–∏:
    1. –°–Ω–∞—á–∞–ª–∞ deepseek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
    2. Fallback –Ω–∞ fireworks_deepseek –ø—Ä–∏ –æ—à–∏–±–∫–µ

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        granularity: –†–µ–∂–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ("short" | "long")
        version_id: ID –≤–µ—Ä—Å–∏–∏ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º
    """
    try:
        logger.info(f"[Task {self.request.id}] Extracting topics for recording {recording_id}, user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing topic extraction...', 'step': 'extract_topics'}
        )

        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            _async_extract_topics(self, recording_id, user_id, granularity, version_id)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error extracting topics: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_extract_topics(
    task_self, recording_id: int, user_id: int, granularity: str, version_id: str | None
) -> dict:
    """
    Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–∏.

    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1. –ü–æ–ø—ã—Ç–∫–∞ —Å deepseek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
    2. Fallback –Ω–∞ fireworks_deepseek –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    from deepseek_module import DeepSeekConfig, TopicExtractor
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        transcription_manager = get_transcription_manager()
        if not transcription_manager.has_master(recording_id, user_id=user_id):
            raise ValueError(
                f"Transcription not found for recording {recording_id}. Please run transcription first."
            )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Loading transcription...', 'step': 'extract_topics'}
        )

        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ segments.txt
        segments_path = transcription_manager.ensure_segments_txt(recording_id, user_id=user_id)

        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
        topics_result = None
        model_used = None
        last_error = None

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: DeepSeek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
        try:
            logger.info(f"[Topics] Trying primary model: deepseek for recording {recording_id}")
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 40, 'status': 'Extracting topics (deepseek)...', 'step': 'extract_topics'}
            )

            deepseek_config = DeepSeekConfig.from_file("config/deepseek_creds.json")
            topic_extractor = TopicExtractor(deepseek_config)

            topics_result = await topic_extractor.extract_topics_from_file(
                segments_file_path=str(segments_path),
                recording_topic=recording.display_name,
                granularity=granularity,
            )
            model_used = "deepseek"
            logger.info(f"[Topics] Successfully extracted with deepseek for recording {recording_id}")

        except Exception as e:
            logger.warning(f"[Topics] DeepSeek failed for recording {recording_id}: {e}. Trying fallback...")
            last_error = e

            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: Fireworks DeepSeek (fallback)
            try:
                logger.info(f"[Topics] Trying fallback model: fireworks_deepseek for recording {recording_id}")
                task_self.update_state(
                    state='PROCESSING',
                    meta={'progress': 50, 'status': 'Extracting topics (fallback)...', 'step': 'extract_topics'}
                )

                deepseek_config = DeepSeekConfig.from_file("config/deepseek_fireworks_creds.json")
                topic_extractor = TopicExtractor(deepseek_config)

                topics_result = await topic_extractor.extract_topics_from_file(
                    segments_file_path=str(segments_path),
                    recording_topic=recording.display_name,
                    granularity=granularity,
                )
                model_used = "fireworks_deepseek"
                logger.info(f"[Topics] Successfully extracted with fireworks_deepseek for recording {recording_id}")

            except Exception as e2:
                logger.error(f"[Topics] All models failed for recording {recording_id}. Last error: {e2}")
                raise ValueError(f"Failed to extract topics with all models. Primary: {last_error}, Fallback: {e2}")

        if not topics_result:
            raise ValueError("Failed to extract topics: no result returned")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 80, 'status': 'Saving topics...', 'step': 'extract_topics'}
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º version_id –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
        if not version_id:
            version_id = transcription_manager.generate_version_id(recording_id, user_id=user_id)

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–¥–º–∏–Ω–∞
        usage_metadata = {
            "model": model_used,
            "prompt_used": "See TopicExtractor code for prompt generation",
            "config": {
                "temperature": deepseek_config.temperature if deepseek_config else None,
                "max_tokens": deepseek_config.max_tokens if deepseek_config else None,
            },
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å usage –∏–∑ API response, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ topics.json
        transcription_manager.add_topics_version(
            recording_id=recording_id,
            version_id=version_id,
            model=model_used,
            granularity=granularity,
            main_topics=topics_result.get("main_topics", []),
            topic_timestamps=topics_result.get("topic_timestamps", []),
            pauses=topics_result.get("long_pauses", []),
            is_active=True,
            usage_metadata=usage_metadata,
            user_id=user_id,
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î (–∞–∫—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        recording.topic_timestamps = topics_result.get("topic_timestamps", [])
        recording.main_topics = topics_result.get("main_topics", [])

        # –ü–æ–º–µ—á–∞–µ–º —ç—Ç–∞–ø –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π
        recording.mark_stage_completed(
            ProcessingStageType.EXTRACT_TOPICS,
            meta={"version_id": version_id, "granularity": granularity, "model": model_used},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return {
            "success": True,
            "version_id": version_id,
            "topics_count": len(topics_result.get("topic_timestamps", [])),
            "main_topics": topics_result.get("main_topics", []),
        }


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.generate_subtitles",
    max_retries=2,
    default_retry_delay=60,
)
def generate_subtitles_task(
    self,
    recording_id: int,
    user_id: int,
    formats: list[str] | None = None,
) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        formats: –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤ ('srt', 'vtt')

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    """
    try:
        logger.info(f"[Task {self.request.id}] Generating subtitles for recording {recording_id}, user {user_id}")

        formats = formats or ["srt", "vtt"]

        self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Initializing subtitle generation...', 'step': 'generate_subtitles'}
        )

        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            _async_generate_subtitles(self, recording_id, user_id, formats)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error generating subtitles: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_generate_subtitles(task_self, recording_id: int, user_id: int, formats: list[str]) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤."""
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        transcription_manager = get_transcription_manager()
        if not transcription_manager.has_master(recording_id, user_id=user_id):
            raise ValueError(
                f"Transcription not found for recording {recording_id}. Please run transcription first."
            )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 40, 'status': 'Generating subtitles...', 'step': 'generate_subtitles'}
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã
        subtitle_paths = transcription_manager.generate_subtitles(
            recording_id=recording_id,
            formats=formats,
            user_id=user_id,
        )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 90, 'status': 'Saving results...', 'step': 'generate_subtitles'}
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
        recording.mark_stage_completed(
            ProcessingStageType.GENERATE_SUBTITLES,
            meta={"formats": formats, "files": subtitle_paths},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        return {
            "success": True,
            "formats": formats,
            "files": subtitle_paths,
        }
