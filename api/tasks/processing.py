"""Celery tasks –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–µ–π —Å multi-tenancy support."""

import asyncio
from pathlib import Path

from celery import Task
from celery.exceptions import SoftTimeLimitExceeded

from api.celery_app import celery_app
from api.repositories.recording_repos import RecordingAsyncRepository
from database.config import DatabaseConfig
from database.manager import DatabaseManager
from logger import get_logger
from models import MeetingRecording, ProcessingStageType, ProcessingStatus
from video_download_module.downloader import ZoomDownloader
from video_processing_module.video_processor import VideoProcessor

logger = get_logger()


class ProcessingTask(Task):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å multi-tenancy."""

    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –∑–∞–¥–∞—á–∏."""
        user_id = kwargs.get("user_id", "unknown")
        recording_id = kwargs.get("recording_id", "unknown")
        logger.error(f"Task {task_id} for user {user_id}, recording {recording_id} failed: {exc!r}")

    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏."""
        user_id = kwargs.get("user_id", "unknown")
        logger.warning(f"Task {task_id} for user {user_id} retrying: {exc}")

    def on_success(self, retval, task_id, args, kwargs):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."""
        user_id = kwargs.get("user_id", "unknown")
        logger.info(f"Task {task_id} for user {user_id} completed successfully")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.download_recording",
    max_retries=3,
    default_retry_delay=600,
)
def download_recording_task(
    self,
    recording_id: int,
    user_id: int,
    force: bool = False,
    manual_override: dict | None = None,
) -> dict:
    """
    –°–∫–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –∏–∑ Zoom (template-driven).

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        force: –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ—Å–ª–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω–æ
        manual_override: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    try:
        logger.info(f"[Task {self.request.id}] Downloading recording {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing download...', 'step': 'download'}
        )

        result = asyncio.run(
            _async_download_recording(self, recording_id, user_id, force, manual_override)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=900, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error downloading: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_download_recording(
    task_self,
    recording_id: int,
    user_id: int,
    force: bool,
    manual_override: dict | None = None,
) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (template-driven)."""
    from api.helpers.config_resolution_helper import resolve_full_config

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        # Resolve config
        full_config, recording = await resolve_full_config(
            session, recording_id, user_id, manual_override
        )

        download_config = full_config.get("download", {})

        # Extract download parameters
        max_file_size_mb = download_config.get("max_file_size_mb", 5000)
        retry_attempts = download_config.get("retry_attempts", 3)

        logger.debug(
            f"Download config for recording {recording_id}: "
            f"max_file_size_mb={max_file_size_mb}, retry_attempts={retry_attempts}"
        )

        recording_repo = RecordingAsyncRepository(session)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º download_url
        download_url = None
        if recording.source and recording.source.meta:
            download_url = recording.source.meta.get("download_url")

        if not download_url:
            raise ValueError("No download URL available. Please sync from Zoom first.")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ —Å–∫–∞—á–∞–Ω–æ —É–∂–µ
        if not force and recording.status == ProcessingStatus.DOWNLOADED and recording.local_video_path:
            if Path(recording.local_video_path).exists():
                return {
                    "success": True,
                    "message": "Already downloaded",
                    "local_video_path": recording.local_video_path,
                }

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 30, 'status': 'Downloading from Zoom...', 'step': 'download'}
        )

        # –°–æ–∑–¥–∞–µ–º downloader
        user_download_dir = f"media/user_{user_id}/video/unprocessed"
        downloader = ZoomDownloader(download_dir=user_download_dir)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ MeetingRecording
        meeting_id = recording.source.source_key if recording.source else str(recording.id)
        file_size = recording.source.meta.get("file_size", 0) if recording.source and recording.source.meta else 0
        download_access_token = recording.source.meta.get("download_access_token") if recording.source and recording.source.meta else None
        passcode = recording.source.meta.get("recording_play_passcode") if recording.source and recording.source.meta else None
        password = recording.source.meta.get("password") if recording.source and recording.source.meta else None
        account = recording.source.meta.get("account") if recording.source and recording.source.meta else None

        meeting_recording = MeetingRecording({
            "id": meeting_id,
            "uuid": meeting_id,
            "topic": recording.display_name,
            "start_time": recording.start_time.isoformat(),
            "duration": recording.duration or 0,
            "account": account or "default",
            "recording_files": [{
                "file_type": "MP4",
                "file_size": file_size,
                "download_url": download_url,
                "recording_type": "shared_screen_with_speaker_view",
                "download_access_token": download_access_token,
            }],
            "password": password,
            "recording_play_passcode": passcode,
        })
        meeting_recording.db_id = recording.id

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 50, 'status': 'Saving video file...', 'step': 'download'}
        )

        # –°–∫–∞—á–∏–≤–∞–µ–º
        success = await downloader.download_recording(meeting_recording, force_download=force)

        if success:
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 90, 'status': 'Updating database...', 'step': 'download'}
            )

            recording.local_video_path = meeting_recording.local_video_path
            recording.status = ProcessingStatus.DOWNLOADED
            await recording_repo.update(recording)
            await session.commit()

            return {
                "success": True,
                "local_video_path": recording.local_video_path,
            }
        else:
            raise Exception("Download failed")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.trim_video",
    max_retries=2,
    default_retry_delay=300,
)
def trim_video_task(
    self,
    recording_id: int,
    user_id: int,
    manual_override: dict | None = None,
) -> dict:
    """
    –û–±—Ä–µ–∑–∞—Ç—å –≤–∏–¥–µ–æ - FFmpeg (—É–¥–∞–ª–µ–Ω–∏–µ —Ç–∏—à–∏–Ω—ã, template-driven).

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ resolved config (user_config < template < manual_override):
    - processing.silence_threshold
    - processing.min_silence_duration
    - processing.padding_before
    - processing.padding_after

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        manual_override: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        logger.info(f"[Task {self.request.id}] Trimming video {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing video trimming...', 'step': 'trim'}
        )

        result = asyncio.run(
            _async_process_video(self, recording_id, user_id, manual_override)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error processing: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_process_video(
    task_self,
    recording_id: int,
    user_id: int,
    manual_override: dict | None = None,
) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ (template-driven)."""
    from api.helpers.config_resolution_helper import resolve_full_config

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        # Resolve config from hierarchy
        full_config, recording = await resolve_full_config(
            session, recording_id, user_id, manual_override
        )

        processing_config = full_config.get("processing", {})

        # Extract processing parameters
        silence_threshold = processing_config.get("silence_threshold", -40.0)
        min_silence_duration = processing_config.get("min_silence_duration", 2.0)
        padding_before = processing_config.get("padding_before", 5.0)
        padding_after = processing_config.get("padding_after", 5.0)

        logger.debug(
            f"Processing config for recording {recording_id}: "
            f"silence_threshold={silence_threshold}, min_silence_duration={min_silence_duration}"
        )

        recording_repo = RecordingAsyncRepository(session)

        if not recording.local_video_path:
            raise ValueError("No video file available. Please download first.")

        if not Path(recording.local_video_path).exists():
            raise ValueError(f"Video file not found: {recording.local_video_path}")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Analyzing video...', 'step': 'process'}
        )

        # –°–æ–∑–¥–∞–µ–º processor —Å ProcessingConfig
        from video_processing_module.config import ProcessingConfig

        user_processed_dir = f"media/user_{user_id}/video/processed"
        config = ProcessingConfig(
            silence_threshold=silence_threshold,
            min_silence_duration=min_silence_duration,
            padding_before=padding_before,
            padding_after=padding_after,
            output_dir=user_processed_dir,
        )
        processor = VideoProcessor(config)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 40, 'status': 'Processing with FFmpeg...', 'step': 'process'}
        )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –∑–≤—É–∫–∞
        success, processed_path = await processor.process_video_with_audio_detection(
            video_path=recording.local_video_path,
            title=recording.display_name,
            start_time=recording.start_time.isoformat(),
        )

        if success and processed_path:
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 60, 'status': 'Extracting audio from processed video...', 'step': 'extract_audio'}
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            import subprocess

            from utils.file_utils import sanitize_filename

            audio_dir = f"media/user_{user_id}/audio/processed"
            Path(audio_dir).mkdir(parents=True, exist_ok=True)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
            safe_title = sanitize_filename(recording.display_name)
            date_suffix = ""
            try:
                date_obj = recording.start_time
                date_suffix = f"_{date_obj.strftime('%y-%m-%d_%H-%M')}"
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã –¥–ª—è –∞—É–¥–∏–æ: {e}")

            audio_filename = f"{safe_title}{date_suffix}_processed.mp3"
            audio_path = str(Path(audio_dir) / audio_filename)

            logger.info(f"üéµ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {recording.display_name}")

            # FFmpeg –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ (64k, 16kHz, mono)
            extract_cmd = [
                "ffmpeg",
                "-i", processed_path,
                "-vn",  # –±–µ–∑ –≤–∏–¥–µ–æ
                "-acodec", "libmp3lame",
                "-ab", "64k",
                "-ar", "16000",
                "-ac", "1",  # mono
                "-y",  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                audio_path,
            ]

            try:
                extract_process = await asyncio.create_subprocess_exec(
                    *extract_cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
                stdout, stderr = await extract_process.communicate()

                if extract_process.returncode == 0 and Path(audio_path).exists():
                    recording.processed_audio_path = str(audio_path)
                    logger.info(f"‚úÖ –ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {audio_path}")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ: {stderr.decode()}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e}")

            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 90, 'status': 'Updating database...', 'step': 'process'}
            )

            recording.processed_video_path = processed_path
            recording.status = ProcessingStatus.PROCESSED
            # VIDEO_PROCESSING - —ç—Ç–æ —á–∞—Å—Ç—å –æ–±—â–µ–≥–æ ProcessingStatus.PROCESSED, –Ω–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º
            await recording_repo.update(recording)
            await session.commit()

            return {
                "success": True,
                "processed_video_path": processed_path,
                "audio_path": audio_path if Path(audio_path).exists() else None,
            }
        else:
            raise Exception("Processing failed")


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.transcribe_recording",
    max_retries=2,
    default_retry_delay=300,
)
def transcribe_recording_task(
    self,
    recording_id: int,
    user_id: int,
    manual_override: dict | None = None,
) -> dict:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ —Å –ê–î–ú–ò–ù–°–ö–ò–ú–ò –∫—Ä–µ–¥–∞–º–∏ (template-driven).

    –í–ê–ñ–ù–û: –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (Fireworks), –ë–ï–ó –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º.
    –î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ extract_topics_task.

    Config parameters used:
    - transcription.language (default: "ru")
    - transcription.prompt (default: "")
    - transcription.temperature (default: 0.0)

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        manual_override: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (–±–µ–∑ —Ç–æ–ø–∏–∫–æ–≤)
    """
    try:
        logger.info(f"[Task {self.request.id}] Transcribing recording {recording_id} for user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing transcription...', 'step': 'transcribe'}
        )

        result = asyncio.run(
            _async_transcribe_recording(self, recording_id, user_id, manual_override)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error transcribing: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_transcribe_recording(
    task_self,
    recording_id: int,
    user_id: int,
    manual_override: dict | None = None,
) -> dict:
    """
    Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å –ê–î–ú–ò–ù–°–ö–ò–ú–ò –ö–†–ï–î–ê–ú–ò (template-driven).

    –í–ê–ñ–ù–û: –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (Fireworks), –±–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º.
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –¥–µ–ª–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ /topics endpoint.

    Config parameters used:
    - transcription.language (default: "ru")
    - transcription.prompt (default: "")
    - transcription.temperature (default: 0.0)
    """
    from api.helpers.config_resolution_helper import resolve_full_config
    from fireworks_module import FireworksConfig, FireworksTranscriptionService
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        # Resolve config from hierarchy
        full_config, recording = await resolve_full_config(
            session, recording_id, user_id, manual_override
        )

        transcription_config = full_config.get("transcription", {})

        # Extract transcription parameters
        language = transcription_config.get("language", "ru")
        user_prompt = transcription_config.get("prompt", "")
        temperature = transcription_config.get("temperature", 0.0)

        logger.debug(
            f"Transcription config for recording {recording_id}: "
            f"language={language}, has_prompt={bool(user_prompt)}, temperature={temperature}"
        )

        recording_repo = RecordingAsyncRepository(session)

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ > –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ > –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ
        audio_path = None

        # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        if recording.processed_audio_path:
            audio_path = Path(recording.processed_audio_path)
            if audio_path.exists():
                audio_files = [audio_path]
            else:
                audio_files = []
        else:
            # Fallback: –∏—â–µ–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –±–µ–∑ processed_audio_path)
            audio_dir = Path(recording.transcription_dir).parent.parent / "audio" / "processed" if recording.transcription_dir else None
            audio_files = []
            if audio_dir and audio_dir.exists():
                for ext in ("*.mp3", "*.wav", "*.m4a"):
                    audio_files = sorted(audio_dir.glob(ext))
                    if audio_files:
                        audio_path = str(audio_files[0])
                        logger.info(f"üéµ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ: {audio_path}")
                        break

        # 2. Fallback –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ
        if not audio_path:
            audio_path = recording.processed_video_path or recording.local_video_path
            if audio_path:
                logger.info(f"üé¨ –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ —Ñ–∞–π–ª (–∞—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ): {audio_path}")

        if not audio_path:
            raise ValueError("No audio or video file available for transcription")

        if not Path(audio_path).exists():
            raise ValueError(f"Audio/video file not found: {audio_path}")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Loading transcription service...', 'step': 'transcribe'}
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ê–î–ú–ò–ù–°–ö–ò–ï –∫—Ä–µ–¥—ã (—Ç–æ–ª—å–∫–æ Fireworks)
        fireworks_config = FireworksConfig.from_file("config/fireworks_creds.json")
        fireworks_service = FireworksTranscriptionService(fireworks_config)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 30, 'status': 'Transcribing audio...', 'step': 'transcribe'}
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç: user_prompt (–∏–∑ config) + display_name
        from transcription_module.service import TranscriptionService

        fireworks_prompt = TranscriptionService._compose_fireworks_prompt(
            user_prompt, recording.display_name
        )

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–µ—Ä–µ–∑ Fireworks API (–¢–û–õ–¨–ö–û —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è, –±–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º language –∏ temperature –∏–∑ resolved config
        transcription_result = await fireworks_service.transcribe_audio(
            audio_path=audio_path,
            language=language,  # ‚Üê from resolved config
            prompt=fireworks_prompt,
        )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 70, 'status': 'Saving transcription...', 'step': 'transcribe'}
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ master.json (–ë–ï–ó topics.json)
        transcription_manager = get_transcription_manager()
        transcription_dir = transcription_manager.get_dir(recording_id)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        words = transcription_result.get("words", [])
        segments = transcription_result.get("segments", [])
        detected_language = transcription_result.get("language", language)

        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        duration = 0.0
        if segments and len(segments) > 0:
            last_segment = segments[-1]
            duration = last_segment.get("end", 0.0)

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–¥–º–∏–Ω–∞ (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏)
        usage_metadata = {
            "model": fireworks_config.model,
            "prompt_used": fireworks_prompt,
            "config": {
                "temperature": temperature,  # ‚Üê from resolved config
                "language": language,  # ‚Üê from resolved config
                "detected_language": detected_language,
                "response_format": fireworks_config.response_format,
                "timestamp_granularities": fireworks_config.timestamp_granularities,
                "preprocessing": fireworks_config.preprocessing,
            },
            "audio_file": {
                "path": str(audio_path),  # Convert Path to string for JSON serialization
                "duration_seconds": duration,
            },
            # –ï—Å–ª–∏ Fireworks API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç usage, –¥–æ–±–∞–≤–ª—è–µ–º —Å—é–¥–∞
            "usage": transcription_result.get("usage"),
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º master.json
        transcription_manager.save_master(
            recording_id=recording_id,
            words=words,
            segments=segments,
            language=language,
            model="fireworks",
            duration=duration,
            usage_metadata=usage_metadata,
            user_id=user_id,
            raw_response=transcription_result,
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—ç—à-—Ñ–∞–π–ª—ã (segments.txt, words.txt)
        transcription_manager.generate_cache_files(recording_id, user_id=user_id)

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 90, 'status': 'Updating database...', 'step': 'transcribe'}
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î (–±–µ–∑ —Ç–æ–ø–∏–∫–æ–≤)
        recording.transcription_dir = str(transcription_dir)
        recording.transcription_info = transcription_result

        # –ü–æ–º–µ—á–∞–µ–º —ç—Ç–∞–ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π
        recording.mark_stage_completed(
            ProcessingStageType.TRANSCRIBE,
            meta={"transcription_dir": str(transcription_dir), "language": language, "model": "fireworks"},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ processing_stages
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        logger.info(
            f"‚úÖ Transcription completed for recording {recording_id}: "
            f"words={len(words)}, segments={len(segments)}, language={language}"
        )

        return {
            "success": True,
            "transcription_dir": str(transcription_dir),
            "language": language,
            "words_count": len(words),
            "segments_count": len(segments),
        }


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.process_recording",
    max_retries=1,
    default_retry_delay=600,
)
def process_recording_task(
    self,
    recording_id: int,
    user_id: int,
    manual_override: dict | None = None,
) -> dict:
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏: download ‚Üí trim ‚Üí transcribe ‚Üí topics ‚Üí upload.

    Template-driven: –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ resolved config (user_config < template < manual_override).

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        manual_override: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ª—é–±—ã–µ –ø–æ–ª—è)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    try:
        logger.info(f"[Task {self.request.id}] Processing recording {recording_id}, user {user_id}")

        from api.helpers.config_resolution_helper import resolve_full_config
        from api.tasks.upload import upload_recording_to_platform
        from database.config import DatabaseConfig
        from database.manager import DatabaseManager

        manual_override = manual_override or {}

        # Resolve configuration from hierarchy using helper
        db_config = DatabaseConfig.from_env()
        db_manager = DatabaseManager(db_config)

        async def _resolve_config_and_presets():
            async with db_manager.async_session() as session:
                # Resolve config
                full_config, output_config, recording = await resolve_full_config(
                    session, recording_id, user_id, manual_override, include_output_config=True
                )

                # Load presets in the same async context
                preset_ids_list = output_config.get("preset_ids", [])
                presets = []
                if preset_ids_list:
                    from api.repositories.template_repos import OutputPresetRepository
                    preset_repo = OutputPresetRepository(session)
                    for preset_id in preset_ids_list:
                        preset = await preset_repo.find_by_id(preset_id, user_id)
                        if preset:
                            presets.append(preset)

                return full_config, output_config, recording, presets

        import asyncio
        full_config, output_config, recording, presets = asyncio.run(_resolve_config_and_presets())

        # Skip blank records
        if recording.blank_record:
            logger.info(
                f"[Task {self.request.id}] Skipping full_pipeline for recording {recording_id}: marked as blank_record "
                f"(duration={recording.duration}min, size={recording.video_file_size} bytes)"
            )

            # Update status to SKIPPED
            async def _mark_skipped():
                async with db_manager.async_session() as session:
                    from api.repositories.recording_repos import RecordingAsyncRepository
                    recording_repo = RecordingAsyncRepository(session)
                    rec = await recording_repo.get_by_id(recording_id, user_id)
                    if rec:
                        rec.status = ProcessingStatus.SKIPPED
                        rec.failed_reason = "Blank record (too short or too small)"
                        await session.commit()

            asyncio.run(_mark_skipped())

            return {
                "task_id": self.request.id,
                "status": "skipped",
                "reason": "blank_record",
                "recording_id": recording_id,
            }

        logger.info(
            f"[Task {self.request.id}] Resolved config for recording {recording_id}: "
            f"template_id={recording.template_id}, has_manual_override={bool(recording.processing_preferences)}"
        )

        # Extract pipeline parameters from resolved config
        processing = full_config.get("processing", {})
        transcription = full_config.get("transcription", {})

        # Pipeline steps
        download = True  # Always download if not already downloaded
        process = processing.get("enable_processing", True)
        transcribe = transcription.get("enable_transcription", True)
        extract_topics = transcription.get("enable_topics", True)
        generate_subs = transcription.get("enable_subtitles", True)

        # Upload configuration from output_config (not full_config!)
        upload = output_config.get("auto_upload", False)
        preset_ids_list = output_config.get("preset_ids", [])

        # Fallback: check in full_config["upload"] for backward compatibility
        if not upload and "upload" in full_config:
            upload = full_config["upload"].get("auto_upload", False)

        # Platforms (can be in either location)
        platforms = output_config.get("default_platforms", [])
        if not platforms and "upload" in full_config:
            platforms = full_config["upload"].get("default_platforms", [])

        # Processing parameters
        granularity = transcription.get("granularity", "long")

        logger.info(
            f"[Task {self.request.id}] Pipeline steps: "
            f"download={download}, process={process}, transcribe={transcribe}, "
            f"extract_topics={extract_topics}, generate_subs={generate_subs}, "
            f"upload={upload}, preset_ids={preset_ids_list}, platforms={platforms}"
        )

        results = {
            "recording_id": recording_id,
            "steps_completed": [],
            "errors": [],
        }

        total_steps = sum([download, process, transcribe, extract_topics, generate_subs, upload and len(platforms) > 0])
        current_step = 0

        # STEP 1: Download
        if download:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Downloading from Zoom...',
                        'step': 'download'
                    }
                )

                # Call async function directly (bypass Celery task wrapper to avoid .run() issues)
                download_result = asyncio.run(
                    _async_download_recording(self, recording_id, user_id, False, manual_override)
                )

                results["steps_completed"].append("download")
                results["download"] = download_result
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Download failed: {str(e)}")
                logger.error(f"Download step failed: {e}")

        # STEP 2: Process
        if process:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Processing video...',
                        'step': 'process'
                    }
                )

                # Call async function directly (bypass Celery task wrapper to avoid .run() issues)
                process_result = asyncio.run(
                    _async_process_video(self, recording_id, user_id, manual_override)
                )

                results["steps_completed"].append("process")
                results["process"] = process_result
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Processing failed: {str(e)}")
                logger.error(f"Processing step failed: {e}")

        # STEP 3: Transcribe
        if transcribe:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Transcribing...',
                        'step': 'transcribe'
                    }
                )

                # Call async function directly (bypass Celery task wrapper to avoid .run() issues)
                transcribe_result = asyncio.run(
                    _async_transcribe_recording(self, recording_id, user_id, manual_override)
                )

                results["steps_completed"].append("transcribe")
                results["transcribe"] = transcribe_result
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Transcription failed: {str(e)}")
                logger.error(f"Transcription step failed: {e}")

        # STEP 4: Extract Topics
        if extract_topics:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Extracting topics...',
                        'step': 'extract_topics'
                    }
                )

                # Call async function directly
                topics_result = asyncio.run(
                    _async_extract_topics(self, recording_id, user_id, granularity, None)
                )

                results["steps_completed"].append("extract_topics")
                results["extract_topics"] = topics_result
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Topic extraction failed: {str(e)}")
                logger.error(f"Topic extraction step failed: {e}")

        # STEP 5: Generate Subtitles
        if generate_subs:
            try:
                self.update_state(
                    state='PROCESSING',
                    meta={
                        'progress': int((current_step / total_steps) * 100),
                        'status': 'Generating subtitles...',
                        'step': 'generate_subtitles'
                    }
                )

                # Get subtitle formats from config
                subtitle_formats = transcription.get("subtitle_formats", ["srt", "vtt"])

                # Call async function directly
                subtitles_result = asyncio.run(
                    _async_generate_subtitles(self, recording_id, user_id, subtitle_formats)
                )

                results["steps_completed"].append("generate_subtitles")
                results["generate_subtitles"] = subtitles_result
                current_step += 1
            except Exception as e:
                results["errors"].append(f"Subtitle generation failed: {str(e)}")
                logger.error(f"Subtitle generation step failed: {e}")

        # STEP 6: Upload
        if upload and (platforms or preset_ids_list):
            # Build platform -> preset_id mapping (presets already loaded at the start)
            preset_map = {preset.platform: preset.id for preset in presets}

            # If platforms not specified, use platforms from presets
            if not platforms and presets:
                platforms = [preset.platform for preset in presets]

            # Extract metadata override from full_config
            # metadata_config is NOT flattened, so it's in its own key
            metadata_override = full_config.get("metadata_config", {})
            if metadata_override:
                logger.info(f"Using metadata_config override for uploads: {list(metadata_override.keys())}")

            upload_task_ids = []
            for platform in platforms:
                try:
                    self.update_state(
                        state='PROCESSING',
                        meta={
                            'progress': int((current_step / total_steps) * 100),
                            'status': f'Uploading to {platform}...',
                            'step': 'upload'
                        }
                    )

                    preset_id = preset_map.get(platform)

                    # Launch upload asynchronously without blocking (Celery best practice)
                    upload_task = upload_recording_to_platform.delay(
                        recording_id, user_id, platform, preset_id, None, metadata_override
                    )

                    upload_task_ids.append({
                        "platform": platform,
                        "task_id": upload_task.id,
                        "preset_id": preset_id,
                    })
                    logger.info(f"Upload task for {platform} launched: {upload_task.id}")
                except Exception as e:
                    results["errors"].append(f"Failed to launch upload to {platform}: {str(e)}")
                    logger.error(f"Failed to launch upload to {platform}: {e}")

            if upload_task_ids:
                results["steps_completed"].append("upload")
                results["upload"] = {
                    "status": "launched",
                    "tasks": upload_task_ids,
                }
                current_step += 1

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        if not results["errors"]:
            results["status"] = "completed"
        elif results["steps_completed"]:
            results["status"] = "partially_completed"
        else:
            results["status"] = "failed"

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": results,
        }

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Full pipeline failed: {exc!r}", exc_info=True)
        raise


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.extract_topics",
    max_retries=2,
    default_retry_delay=300,
)
def extract_topics_task(
    self,
    recording_id: int,
    user_id: int,
    granularity: str = "long",
    version_id: str | None = None,
) -> dict:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–µ–º—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—Å–∫–∏–µ –∫—Ä–µ–¥—ã).

    –ú–æ–¥–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –∏ —Ñ–æ–ª–ª–±—ç–∫–∞–º–∏:
    1. –°–Ω–∞—á–∞–ª–∞ deepseek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
    2. Fallback –Ω–∞ fireworks_deepseek –ø—Ä–∏ –æ—à–∏–±–∫–µ

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        granularity: –†–µ–∂–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ("short" | "long")
        version_id: ID –≤–µ—Ä—Å–∏–∏ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º
    """
    try:
        logger.info(f"[Task {self.request.id}] Extracting topics for recording {recording_id}, user {user_id}")

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Initializing topic extraction...', 'step': 'extract_topics'}
        )

        result = asyncio.run(
            _async_extract_topics(self, recording_id, user_id, granularity, version_id)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=600, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error extracting topics: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_extract_topics(
    task_self, recording_id: int, user_id: int, granularity: str, version_id: str | None
) -> dict:
    """
    Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–∏.

    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1. –ü–æ–ø—ã—Ç–∫–∞ —Å deepseek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
    2. Fallback –Ω–∞ fireworks_deepseek –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    from deepseek_module import DeepSeekConfig, TopicExtractor
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        transcription_manager = get_transcription_manager()
        if not transcription_manager.has_master(recording_id, user_id=user_id):
            raise ValueError(
                f"Transcription not found for recording {recording_id}. Please run transcription first."
            )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Loading transcription...', 'step': 'extract_topics'}
        )

        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ segments.txt
        segments_path = transcription_manager.ensure_segments_txt(recording_id, user_id=user_id)

        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
        topics_result = None
        model_used = None
        last_error = None

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: DeepSeek (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
        try:
            logger.info(f"[Topics] Trying primary model: deepseek for recording {recording_id}")
            task_self.update_state(
                state='PROCESSING',
                meta={'progress': 40, 'status': 'Extracting topics (deepseek)...', 'step': 'extract_topics'}
            )

            deepseek_config = DeepSeekConfig.from_file("config/deepseek_creds.json")
            topic_extractor = TopicExtractor(deepseek_config)

            topics_result = await topic_extractor.extract_topics_from_file(
                segments_file_path=str(segments_path),
                recording_topic=recording.display_name,
                granularity=granularity,
            )
            model_used = "deepseek"
            logger.info(f"[Topics] Successfully extracted with deepseek for recording {recording_id}")

        except Exception as e:
            logger.warning(f"[Topics] DeepSeek failed for recording {recording_id}: {e}. Trying fallback...")
            last_error = e

            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: Fireworks DeepSeek (fallback)
            try:
                logger.info(f"[Topics] Trying fallback model: fireworks_deepseek for recording {recording_id}")
                task_self.update_state(
                    state='PROCESSING',
                    meta={'progress': 50, 'status': 'Extracting topics (fallback)...', 'step': 'extract_topics'}
                )

                deepseek_config = DeepSeekConfig.from_file("config/deepseek_fireworks_creds.json")
                topic_extractor = TopicExtractor(deepseek_config)

                topics_result = await topic_extractor.extract_topics_from_file(
                    segments_file_path=str(segments_path),
                    recording_topic=recording.display_name,
                    granularity=granularity,
                )
                model_used = "fireworks_deepseek"
                logger.info(f"[Topics] Successfully extracted with fireworks_deepseek for recording {recording_id}")

            except Exception as e2:
                logger.error(f"[Topics] All models failed for recording {recording_id}. Last error: {e2}")
                raise ValueError(f"Failed to extract topics with all models. Primary: {last_error}, Fallback: {e2}")

        if not topics_result:
            raise ValueError("Failed to extract topics: no result returned")

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 80, 'status': 'Saving topics...', 'step': 'extract_topics'}
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º version_id –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
        if not version_id:
            version_id = transcription_manager.generate_version_id(recording_id, user_id=user_id)

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–¥–º–∏–Ω–∞
        usage_metadata = {
            "model": model_used,
            "prompt_used": "See TopicExtractor code for prompt generation",
            "config": {
                "temperature": deepseek_config.temperature if deepseek_config else None,
                "max_tokens": deepseek_config.max_tokens if deepseek_config else None,
            },
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å usage –∏–∑ API response, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ topics.json
        transcription_manager.add_topics_version(
            recording_id=recording_id,
            version_id=version_id,
            model=model_used,
            granularity=granularity,
            main_topics=topics_result.get("main_topics", []),
            topic_timestamps=topics_result.get("topic_timestamps", []),
            pauses=topics_result.get("long_pauses", []),
            is_active=True,
            usage_metadata=usage_metadata,
            user_id=user_id,
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î (–∞–∫—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        recording.topic_timestamps = topics_result.get("topic_timestamps", [])
        recording.main_topics = topics_result.get("main_topics", [])

        # –ü–æ–º–µ—á–∞–µ–º —ç—Ç–∞–ø –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π
        recording.mark_stage_completed(
            ProcessingStageType.EXTRACT_TOPICS,
            meta={"version_id": version_id, "granularity": granularity, "model": model_used},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return {
            "success": True,
            "version_id": version_id,
            "topics_count": len(topics_result.get("topic_timestamps", [])),
            "main_topics": topics_result.get("main_topics", []),
        }


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.generate_subtitles",
    max_retries=2,
    default_retry_delay=60,
)
def generate_subtitles_task(
    self,
    recording_id: int,
    user_id: int,
    formats: list[str] | None = None,
) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        formats: –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤ ('srt', 'vtt')

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    """
    try:
        logger.info(f"[Task {self.request.id}] Generating subtitles for recording {recording_id}, user {user_id}")

        formats = formats or ["srt", "vtt"]

        self.update_state(
            state='PROCESSING',
            meta={'progress': 20, 'status': 'Initializing subtitle generation...', 'step': 'generate_subtitles'}
        )

        result = asyncio.run(
            _async_generate_subtitles(self, recording_id, user_id, formats)
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "result": result,
        }

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error generating subtitles: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_generate_subtitles(task_self, recording_id: int, user_id: int, formats: list[str]) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤."""
    from transcription_module.manager import get_transcription_manager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)

    async with db_manager.async_session() as session:
        recording_repo = RecordingAsyncRepository(session)

        recording = await recording_repo.get_by_id(recording_id, user_id)
        if not recording:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        transcription_manager = get_transcription_manager()
        if not transcription_manager.has_master(recording_id, user_id=user_id):
            raise ValueError(
                f"Transcription not found for recording {recording_id}. Please run transcription first."
            )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 40, 'status': 'Generating subtitles...', 'step': 'generate_subtitles'}
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã
        subtitle_paths = transcription_manager.generate_subtitles(
            recording_id=recording_id,
            formats=formats,
            user_id=user_id,
        )

        task_self.update_state(
            state='PROCESSING',
            meta={'progress': 90, 'status': 'Saving results...', 'step': 'generate_subtitles'}
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
        recording.mark_stage_completed(
            ProcessingStageType.GENERATE_SUBTITLES,
            meta={"formats": formats, "files": subtitle_paths},
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        from api.helpers.status_manager import update_aggregate_status
        update_aggregate_status(recording)

        await recording_repo.update(recording)
        await session.commit()

        return {
            "success": True,
            "formats": formats,
            "files": subtitle_paths,
        }


@celery_app.task(
    bind=True,
    base=ProcessingTask,
    name="api.tasks.processing.batch_transcribe_recording",
    max_retries=3,
    default_retry_delay=300,
)
def batch_transcribe_recording_task(
    self,
    recording_id: int,
    user_id: int,
    batch_id: str,
    poll_interval: float = 10.0,
    max_wait_time: float = 3600.0,
) -> dict:
    """
    Polling –¥–ª—è Fireworks Batch API transcription.

    –≠—Ç–æ—Ç task —Å–æ–∑–¥–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ submit_batch_transcription() –∏ –∂–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è batch job.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç polling –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∫–∞–∂–¥—ã–µ poll_interval —Å–µ–∫—É–Ω–¥.

    Args:
        recording_id: ID –∑–∞–ø–∏—Å–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        batch_id: ID batch job –æ—Ç Fireworks
        poll_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ (—Å–µ–∫—É–Ω–¥—ã)
        max_wait_time: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    """
    try:
        logger.info(
            f"[Task {self.request.id}] Batch transcription polling | recording={recording_id} | user={user_id} | batch_id={batch_id}"
        )

        self.update_state(
            state='PROCESSING',
            meta={'progress': 10, 'status': 'Waiting for batch transcription...', 'step': 'batch_transcribe'}
        )

        result = asyncio.run(
            _async_poll_batch_transcription(
                self,
                recording_id,
                user_id,
                batch_id,
                poll_interval,
                max_wait_time,
            )
        )

        return {
            "task_id": self.request.id,
            "status": "completed",
            "recording_id": recording_id,
            "batch_id": batch_id,
            "result": result,
        }

    except TimeoutError as exc:
        logger.error(
            f"[Task {self.request.id}] Batch transcription timeout | batch_id={batch_id} | max_wait={max_wait_time}s"
        )
        raise self.retry(countdown=600, exc=exc)

    except SoftTimeLimitExceeded:
        logger.error(f"[Task {self.request.id}] Soft time limit exceeded")
        raise self.retry(countdown=900, exc=SoftTimeLimitExceeded())

    except Exception as exc:
        logger.error(f"[Task {self.request.id}] Error in batch transcription: {exc!r}", exc_info=True)
        raise self.retry(exc=exc)


async def _async_poll_batch_transcription(
    task_self,
    recording_id: int,
    user_id: int,
    batch_id: str,
    poll_interval: float,
    max_wait_time: float,
) -> dict:
    """Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è polling batch transcription."""
    import time

    from fireworks_module import FireworksConfig, FireworksTranscriptionService
    from transcription_module.manager import TranscriptionManager

    db_config = DatabaseConfig.from_env()
    db_manager = DatabaseManager(db_config)
    session = await db_manager.async_session()

    try:
        recording_repo = RecordingAsyncRepository(session)
        recording_db = await recording_repo.find_by_id(recording_id, user_id)

        if not recording_db:
            raise ValueError(f"Recording {recording_id} not found for user {user_id}")

        recording = MeetingRecording.from_db_model(recording_db)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Fireworks service
        fireworks_config = FireworksConfig.from_file("config/fireworks_creds.json")
        fireworks_service = FireworksTranscriptionService(fireworks_config)

        # Polling loop
        start_time = time.time()
        attempt = 0

        while True:
            attempt += 1
            elapsed = time.time() - start_time

            if elapsed > max_wait_time:
                raise TimeoutError(
                    f"Batch transcription {batch_id} –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ {max_wait_time}s (–ø–æ–ø—ã—Ç–æ–∫: {attempt})"
                )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
            status_response = await fireworks_service.check_batch_status(batch_id)
            status = status_response.get("status", "unknown")

            # –û–±–Ω–æ–≤–ª—è–µ–º progress (–ø—Ä–∏–º–µ—Ä–Ω–æ)
            progress = min(20 + int((elapsed / max_wait_time) * 60), 80)
            task_self.update_state(
                state='PROCESSING',
                meta={
                    'progress': progress,
                    'status': f'Batch transcribing... ({status}, {elapsed:.0f}s)',
                    'step': 'batch_transcribe',
                    'batch_id': batch_id,
                    'attempt': attempt,
                }
            )

            if status == "completed":
                logger.info(
                    f"[Batch Transcription] Completed ‚úÖ | batch_id={batch_id} | elapsed={elapsed:.1f}s | attempts={attempt}"
                )

                task_self.update_state(
                    state='PROCESSING',
                    meta={'progress': 85, 'status': 'Parsing batch result...', 'step': 'batch_transcribe'}
                )

                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                transcription_result = await fireworks_service.get_batch_result(batch_id)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–∫–∞–∫ –æ–±—ã—á–Ω–æ)
                transcription_manager = TranscriptionManager()

                task_self.update_state(
                    state='PROCESSING',
                    meta={'progress': 90, 'status': 'Saving transcription...', 'step': 'batch_transcribe'}
                )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º master.json
                words = transcription_result.get("words", [])
                segments = transcription_result.get("segments", [])
                language = transcription_result.get("language", "ru")

                master_data = {
                    "text": transcription_result.get("text", ""),
                    "segments": segments,
                    "words": words,
                    "language": language,
                }

                transcription_manager.save_master(
                    recording_id=recording_id,
                    master_data=master_data,
                    user_id=user_id,
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
                recording.transcription_path = transcription_manager.get_dir(recording_id, user_id=user_id)
                recording.mark_stage_completed(
                    ProcessingStageType.TRANSCRIBE,
                    meta={
                        "batch_id": batch_id,
                        "language": language,
                        "words_count": len(words),
                        "segments_count": len(segments),
                        "elapsed_seconds": elapsed,
                    },
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
                from api.helpers.status_manager import update_aggregate_status
                update_aggregate_status(recording)

                await recording_repo.update(recording)
                await session.commit()

                return {
                    "success": True,
                    "batch_id": batch_id,
                    "language": language,
                    "elapsed_seconds": elapsed,
                    "attempts": attempt,
                }

            logger.debug(
                f"[Batch Transcription] Polling | batch_id={batch_id} | status={status} | attempt={attempt} | elapsed={elapsed:.1f}s"
            )

            await asyncio.sleep(poll_interval)

    finally:
        await session.close()
