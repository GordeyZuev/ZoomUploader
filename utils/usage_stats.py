"""–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π"""

import json
from pathlib import Path
from typing import Any


def analyze_transcription_usage(user_id: int, recording_id: int | None = None) -> dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        recording_id: ID –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ None - –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π)

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
    script_dir = Path(__file__).parent.parent
    base_path = script_dir / f"media/user_{user_id}/transcriptions"

    if not base_path.exists():
        return {"error": f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {base_path}"}

    results = []

    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω recording_id, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ
    if recording_id:
        recording_dirs = [base_path / str(recording_id)]
    else:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏
        recording_dirs = [d for d in base_path.iterdir() if d.is_dir()]

    for rec_dir in recording_dirs:
        if not rec_dir.exists():
            continue

        master_json = rec_dir / "master.json"
        topics_json = rec_dir / "topics.json"

        rec_stats = {
            "recording_id": rec_dir.name,
            "transcription": None,
            "topics": [],
        }

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (master.json)
        if master_json.exists():
            try:
                with open(master_json, "r", encoding="utf-8") as f:
                    data = json.load(f)

                metadata = data.get("_metadata", {})
                rec_stats["transcription"] = {
                    "model": metadata.get("model", "unknown"),
                    "duration_seconds": metadata.get("audio_file", {}).get("duration_seconds", 0),
                    "duration_minutes": round(metadata.get("audio_file", {}).get("duration_seconds", 0) / 60, 2),
                    "language": data.get("language", "unknown"),
                    "words_count": data.get("stats", {}).get("words_count", 0),
                    "segments_count": data.get("stats", {}).get("segments_count", 0),
                    "config": metadata.get("config", {}),
                    "usage": metadata.get("usage"),  # –ï—Å–ª–∏ API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç usage
                    "created_at": data.get("created_at"),
                }
            except Exception as e:
                rec_stats["transcription"] = {"error": str(e)}

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø–∏–∫–∏ (topics.json)
        if topics_json.exists():
            try:
                with open(topics_json, "r", encoding="utf-8") as f:
                    topics_data = json.load(f)

                for version in topics_data.get("versions", []):
                    metadata = version.get("_metadata", {})
                    rec_stats["topics"].append({
                        "version_id": version.get("id"),
                        "model": metadata.get("model", "unknown"),
                        "granularity": version.get("granularity"),
                        "is_active": version.get("is_active"),
                        "topics_count": len(version.get("topic_timestamps", [])),
                        "main_topics": version.get("main_topics", []),
                        "config": metadata.get("config", {}),
                        "created_at": version.get("created_at"),
                    })
            except Exception as e:
                rec_stats["topics"] = [{"error": str(e)}]

        results.append(rec_stats)

    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    summary = {
        "total_recordings": len(results),
        "transcription_models": {},
        "topic_models": {},
        "total_duration_minutes": 0,
        "total_words": 0,
        "total_segments": 0,
    }

    for rec in results:
        if rec["transcription"] and "error" not in rec["transcription"]:
            trans = rec["transcription"]
            model = trans["model"]
            summary["transcription_models"][model] = summary["transcription_models"].get(model, 0) + 1
            summary["total_duration_minutes"] += trans.get("duration_minutes", 0)
            summary["total_words"] += trans.get("words_count", 0)
            summary["total_segments"] += trans.get("segments_count", 0)

        for topic in rec.get("topics", []):
            if "error" not in topic:
                model = topic["model"]
                summary["topic_models"][model] = summary["topic_models"].get(model, 0) + 1

    return {
        "summary": summary,
        "recordings": results,
    }


def print_usage_report(user_id: int, recording_id: int | None = None):
    """–ö—Ä–∞—Å–∏–≤–æ –ø–µ—á–∞—Ç–∞–µ—Ç –æ—Ç—á–µ—Ç –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏."""
    stats = analyze_transcription_usage(user_id, recording_id)

    if "error" in stats:
        print(f"‚ùå –û—à–∏–±–∫–∞: {stats['error']}")
        return

    summary = stats["summary"]

    print("\n" + "=" * 80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –¢–û–ö–ï–ù–û–í –ò –ú–û–î–ï–õ–ï–ô")
    print("=" * 80)

    print(f"\nüìÅ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {summary['total_recordings']}")
    print(f"‚è±Ô∏è  –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {summary['total_duration_minutes']:.1f} –º–∏–Ω—É—Ç ({summary['total_duration_minutes'] / 60:.1f} —á–∞—Å–æ–≤)")
    print(f"üìù –í—Å–µ–≥–æ —Å–ª–æ–≤: {summary['total_words']:,}")
    print(f"üéØ –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {summary['total_segments']:,}")

    print("\nü§ñ –ú–û–î–ï–õ–ò –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò:")
    for model, count in summary["transcription_models"].items():
        print(f"   ‚Ä¢ {model}: {count} –∑–∞–ø–∏—Å–µ–π")

    if summary["topic_models"]:
        print("\nüéì –ú–û–î–ï–õ–ò –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –¢–û–ü–ò–ö–û–í:")
        for model, count in summary["topic_models"].items():
            print(f"   ‚Ä¢ {model}: {count} –≤–µ—Ä—Å–∏–π")

    print("\n" + "-" * 80)
    print("üìã –î–ï–¢–ê–õ–ò –ü–û –ó–ê–ü–ò–°–Ø–ú:")
    print("-" * 80)

    for rec in stats["recordings"]:
        print(f"\nüé¨ Recording ID: {rec['recording_id']}")

        if rec["transcription"]:
            trans = rec["transcription"]
            if "error" not in trans:
                print("   üìπ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:")
                print(f"      ‚Ä¢ –ú–æ–¥–µ–ª—å: {trans['model']}")
                print(f"      ‚Ä¢ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {trans['duration_minutes']} –º–∏–Ω")
                print(f"      ‚Ä¢ –Ø–∑—ã–∫: {trans['language']}")
                print(f"      ‚Ä¢ –°–ª–æ–≤: {trans['words_count']:,}")
                print(f"      ‚Ä¢ –°–µ–≥–º–µ–Ω—Ç–æ–≤: {trans['segments_count']}")
                print(f"      ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ: {trans['created_at']}")
                if trans.get("usage"):
                    print(f"      ‚Ä¢ Usage: {trans['usage']}")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {trans['error']}")

        if rec["topics"]:
            for topic in rec["topics"]:
                if "error" not in topic:
                    print(f"   üéì –¢–æ–ø–∏–∫–∏ (–≤–µ—Ä—Å–∏—è {topic['version_id']}):")
                    print(f"      ‚Ä¢ –ú–æ–¥–µ–ª—å: {topic['model']}")
                    print(f"      ‚Ä¢ –†–µ–∂–∏–º: {topic['granularity']}")
                    print(f"      ‚Ä¢ –ê–∫—Ç–∏–≤–Ω–∞: {'‚úÖ' if topic['is_active'] else '‚ùå'}")
                    print(f"      ‚Ä¢ –¢–æ–ø–∏–∫–æ–≤: {topic['topics_count']}")
                    print(f"      ‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã: {', '.join(topic['main_topics'])}")
                    print(f"      ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ: {topic['created_at']}")
                else:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ —Ç–æ–ø–∏–∫–æ–≤: {topic['error']}")

    print("\n" + "=" * 80 + "\n")


def export_usage_to_json(user_id: int, output_file: str = "usage_report.json"):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON —Ñ–∞–π–ª."""
    stats = analyze_transcription_usage(user_id)

    output_path = Path(output_file)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤: {output_path.absolute()}")


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python utils/usage_stats.py <user_id> [recording_id]")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python utils/usage_stats.py 4                  # –í—Å–µ –∑–∞–ø–∏—Å–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 4")
        print("  python utils/usage_stats.py 4 21               # –¢–æ–ª—å–∫–æ –∑–∞–ø–∏—Å—å 21")
        print("  python utils/usage_stats.py 4 --export         # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON")
        sys.exit(1)

    user_id = int(sys.argv[1])

    if len(sys.argv) > 2 and sys.argv[2] == "--export":
        export_usage_to_json(user_id)
    elif len(sys.argv) > 2:
        recording_id = int(sys.argv[2])
        print_usage_report(user_id, recording_id)
    else:
        print_usage_report(user_id)

