"""Subtitle generator from transcriptions (SRT and VTT formats)"""

import os
import re
from datetime import timedelta
from pathlib import Path

from logger import get_logger

logger = get_logger()


class SubtitleEntry:
    """Single subtitle entry"""

    def __init__(self, start_time: timedelta, end_time: timedelta, text: str):
        self.start_time = start_time
        self.end_time = end_time
        self.text = text.strip()

    def __repr__(self) -> str:
        return f"SubtitleEntry({self.start_time} -> {self.end_time}: {self.text[:50]}...)"


class SubtitleGenerator:
    """Generate subtitles from transcription files"""

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫: [HH:MM:SS - HH:MM:SS]
    TIMESTAMP_PATTERN = re.compile(r"\[(\d{2}):(\d{2}):(\d{2})\s*-\s*(\d{2}):(\d{2}):(\d{2})\]\s*(.*)")

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ —Å –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞–º–∏: [HH:MM:SS.mmm - HH:MM:SS.mmm]
    TIMESTAMP_PATTERN_MS = re.compile(
        r"\[(\d{2}):(\d{2}):(\d{2})\.(\d{3})\s*-\s*(\d{2}):(\d{2}):(\d{2})\.(\d{3})\]\s*(.*)"
    )

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ª–æ–≤ —Å –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞–º–∏ (legacy)
    WORDS_TIMESTAMP_PATTERN = re.compile(
        r"\[(\d{2}):(\d{2}):(\d{2})\.(\d{3})\s*-\s*(\d{2}):(\d{2}):(\d{2})\.(\d{3})\]\s*(.*)"
    )

    def __init__(self, max_chars_per_line: int = 42, max_lines: int = 2):
        """
        Args:
            max_chars_per_line: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ —Å—É–±—Ç–∏—Ç—Ä–∞
            max_lines: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –æ–¥–Ω–æ–º —Å—É–±—Ç–∏—Ç—Ä–µ
        """
        self.max_chars_per_line = max_chars_per_line
        self.max_lines = max_lines

    def parse_transcription_file(self, file_path: str) -> list[SubtitleEntry]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ SubtitleEntry
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        entries = []

        with open(file_path, encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue

                match_ms = self.TIMESTAMP_PATTERN_MS.match(line)
                match_s = self.TIMESTAMP_PATTERN.match(line) if not match_ms else None

                if match_ms or match_s:
                    try:
                        if match_ms:
                            start_h, start_m, start_s, start_ms = map(int, match_ms.groups()[:4])
                            end_h, end_m, end_s, end_ms = map(int, match_ms.groups()[4:8])
                            text = match_ms.groups()[8]
                            start_time = timedelta(
                                hours=start_h, minutes=start_m, seconds=start_s, milliseconds=start_ms
                            )
                            end_time = timedelta(hours=end_h, minutes=end_m, seconds=end_s, milliseconds=end_ms)
                        else:
                            start_h, start_m, start_s = map(int, match_s.groups()[:3])
                            end_h, end_m, end_s = map(int, match_s.groups()[3:6])
                            text = match_s.groups()[6]
                            start_time = timedelta(hours=start_h, minutes=start_m, seconds=start_s)
                            end_time = timedelta(hours=end_h, minutes=end_m, seconds=end_s)

                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {line_num} –≤ —Ñ–∞–π–ª–µ {file_path}: {line[:50]}... - {e}")
                        continue

                    if text.strip():
                        entries.append(SubtitleEntry(start_time, end_time, text))
        return entries

    def parse_words_file(self, file_path: str) -> list[SubtitleEntry]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–æ —Å–ª–æ–≤–∞–º–∏ –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏—Ö –≤ —Å—É–±—Ç–∏—Ç—Ä—ã.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–æ —Å–ª–æ–≤–∞–º–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ SubtitleEntry (—Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞)
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        words = []
        total_lines = 0
        parsed_lines = 0

        logger.info(f"üìñ –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ words: {file_path}")

        with open(file_path, encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                total_lines += 1
                line = line.strip()
                if not line:
                    continue

                match = self.WORDS_TIMESTAMP_PATTERN.match(line)
                if match:
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞–º–∏
                        start_h, start_m, start_s, start_ms = map(int, match.groups()[:4])
                        end_h, end_m, end_s, end_ms = map(int, match.groups()[4:8])
                        word_text = match.groups()[8]

                        if word_text.strip():
                            # –°–æ–∑–¥–∞–µ–º timedelta –æ–±—ä–µ–∫—Ç—ã —Å –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞–º–∏
                            start_time = timedelta(
                                hours=start_h, minutes=start_m, seconds=start_s, milliseconds=start_ms
                            )
                            end_time = timedelta(hours=end_h, minutes=end_m, seconds=end_s, milliseconds=end_ms)

                            words.append(
                                {
                                    "start": start_time,
                                    "end": end_time,
                                    "text": word_text.strip(),
                                }
                            )
                            parsed_lines += 1
                    except (ValueError, IndexError) as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {line_num} –≤ —Ñ–∞–π–ª–µ {file_path}: {line[:50]}... - {e}")
                        continue
                else:
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ª–æ–≥
                    if line_num <= 5:
                        logger.debug(
                            f"–°—Ç—Ä–æ–∫–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É: line_num={line_num} | preview={line[:50]}... | file={file_path}"
                        )

        logger.info(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_lines} —Å—Ç—Ä–æ–∫, —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {parsed_lines} —Å–ª–æ–≤")

        if not words:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–ª–æ–≤–∞ –∏–∑ —Ñ–∞–π–ª–∞ {file_path}. –§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.")

        logger.info(f"üîÑ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ {len(words)} —Å–ª–æ–≤ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã...")
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã
        entries = self._group_words_into_subtitles(words)
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(entries)} —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∏–∑ {len(words)} —Å–ª–æ–≤")

        return entries

    def _group_words_into_subtitles(
        self, words: list[dict], max_duration_seconds: float = 5.0, pause_threshold_seconds: float = 0.5
    ) -> list[SubtitleEntry]:
        """
        –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–ª–æ–≤–∞ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø–∞—É–∑.

        Args:
            words: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏ 'start', 'end', 'text' (timedelta)
            max_duration_seconds: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—É–±—Ç–∏—Ç—Ä–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            pause_threshold_seconds: –ü–æ—Ä–æ–≥ –ø–∞—É–∑—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ —Å—É–±—Ç–∏—Ç—Ä–∞ (—Å–µ–∫—É–Ω–¥—ã)

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ SubtitleEntry
        """
        if not words:
            return []

        entries = []
        current_group = []
        current_start = None

        for word in words:
            word_start = word["start"]
            word_end = word["end"]

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –≥—Ä—É–ø–ø—ã
            if current_start is None:
                current_start = word_start

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
            should_start_new = False

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –±–æ–ª—å—à–µ –ø–æ—Ä–æ–≥–∞
            if current_group:
                last_word_end = current_group[-1]["end"]
                pause_duration = (word_start - last_word_end).total_seconds()
                if pause_duration > pause_threshold_seconds:
                    should_start_new = True

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—É—â–µ–π –≥—Ä—É–ø–ø—ã –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º—É–º
            if not should_start_new:
                group_duration = (word_end - current_start).total_seconds()
                if group_duration > max_duration_seconds:
                    should_start_new = True

            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é
            if should_start_new and current_group:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–≤ —Ç–µ–∫—É—â–µ–π –≥—Ä—É–ø–ø—ã
                group_text = " ".join(w["text"] for w in current_group)
                group_start = current_start
                group_end = current_group[-1]["end"]

                entries.append(SubtitleEntry(group_start, group_end, group_text))

                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
                current_group = [word]
                current_start = word_start
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
                current_group.append(word)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
        if current_group:
            group_text = " ".join(w["text"] for w in current_group)
            group_start = current_start
            group_end = current_group[-1]["end"]
            entries.append(SubtitleEntry(group_start, group_end, group_text))

        return entries

    def _format_timedelta_srt(self, td: timedelta) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç timedelta –≤ —Ñ–æ—Ä–º–∞—Ç SRT: HH:MM:SS,mmm"""
        total_seconds = int(td.total_seconds())
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60
        milliseconds = int(td.microseconds / 1000)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

    def _format_timedelta_vtt(self, td: timedelta) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç timedelta –≤ —Ñ–æ—Ä–º–∞—Ç VTT: HH:MM:SS.mmm"""
        total_seconds = int(td.total_seconds())
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60
        milliseconds = int(td.microseconds / 1000)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}"

    def _split_text(self, text: str) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ —Å —É—á–µ—Ç–æ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã.

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        """
        words = text.split()
        lines = []
        current_line = []
        current_length = 0

        for word in words:
            word_length = len(word)

            # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç, –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
            if current_length + word_length + (1 if current_line else 0) > self.max_chars_per_line:
                if current_line:
                    lines.append(" ".join(current_line))
                    current_line = []
                    current_length = 0

                # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if len(lines) >= self.max_lines:
                    break

            current_line.append(word)
            current_length += word_length + (1 if len(current_line) > 1 else 0)

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–ª–æ–≤–∞
        if current_line and len(lines) < self.max_lines:
            lines.append(" ".join(current_line))

        return lines if lines else [text[: self.max_chars_per_line]]

    def generate_srt(self, entries: list[SubtitleEntry], output_path: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SRT.

        Args:
            entries: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        with open(output_path, "w", encoding="utf-8") as f:
            for index, entry in enumerate(entries, start=1):
                # –ù–æ–º–µ—Ä —Å—É–±—Ç–∏—Ç—Ä–∞
                f.write(f"{index}\n")

                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                start_str = self._format_timedelta_srt(entry.start_time)
                end_str = self._format_timedelta_srt(entry.end_time)
                f.write(f"{start_str} --> {end_str}\n")

                # –¢–µ–∫—Å—Ç (—Ä–∞–∑–±–∏—Ç—ã–π –Ω–∞ —Å—Ç—Ä–æ–∫–∏)
                lines = self._split_text(entry.text)
                for line in lines:
                    f.write(f"{line}\n")

                # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏
                f.write("\n")

        return output_path

    def generate_vtt(self, entries: list[SubtitleEntry], output_path: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ VTT.

        Args:
            entries: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        with open(output_path, "w", encoding="utf-8") as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ VTT
            f.write("WEBVTT\n\n")

            for entry in entries:
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                start_str = self._format_timedelta_vtt(entry.start_time)
                end_str = self._format_timedelta_vtt(entry.end_time)
                f.write(f"{start_str} --> {end_str}\n")

                # –¢–µ–∫—Å—Ç (—Ä–∞–∑–±–∏—Ç—ã–π –Ω–∞ —Å—Ç—Ä–æ–∫–∏)
                lines = self._split_text(entry.text)
                for line in lines:
                    f.write(f"{line}\n")

                # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏
                f.write("\n")

        return output_path

    def generate_from_transcription(
        self, transcription_path: str, output_dir: str | None = None, formats: list[str] = None
    ) -> dict[str, str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
        –û–∂–∏–¥–∞–µ—Ç—Å—è –≥–æ—Ç–æ–≤—ã–π segments.txt (—Å –º—Å); –¥—Ä—É–≥–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º.

        Args:
            transcription_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ç–∞ –∂–µ, —á—Ç–æ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è)
            formats: –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ['srt', 'vtt'] (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–±–∞)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º: {'srt': path, 'vtt': path}
        """
        if formats is None:
            formats = ["srt", "vtt"]

        if output_dir is None:
            output_dir = os.path.dirname(transcription_path)

        os.makedirs(output_dir, exist_ok=True)

        entries = []
        base_name = "subtitles"

        if os.path.isdir(transcription_path):
            segments_path = os.path.join(transcription_path, "segments.txt")
            if os.path.exists(segments_path):
                logger.info(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º segments.txt: {segments_path}")
                entries = self.parse_transcription_file(segments_path)
            else:
                raise FileNotFoundError(f"–í –ø–∞–ø–∫–µ –Ω–µ—Ç segments.txt: {transcription_path}")
        else:
            if Path(transcription_path).name == "segments.txt":
                logger.info(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º segments.txt: {transcription_path}")
                entries = self.parse_transcription_file(transcription_path)
            else:
                raise FileNotFoundError(
                    f"–û–∂–∏–¥–∞–µ—Ç—Å—è segments.txt –∏–ª–∏ –ø–∞–ø–∫–∞ —Å segments.txt, –ø–æ–ª—É—á–µ–Ω–æ: {transcription_path}"
                )

        if not entries:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∑–∞–ø–∏—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {transcription_path}")

        result = {}

        if "srt" in formats:
            srt_path = os.path.join(output_dir, f"{base_name}.srt")
            self.generate_srt(entries, srt_path)
            result["srt"] = srt_path

        if "vtt" in formats:
            vtt_path = os.path.join(output_dir, f"{base_name}.vtt")
            self.generate_vtt(entries, vtt_path)
            result["vtt"] = vtt_path

        return result
